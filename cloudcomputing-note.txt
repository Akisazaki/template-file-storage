Jik-Soo Kim, Ph.D
jiksoo@mju.ac.kr




클라우드 컴퓨팅과 빅데이터에 대한 개념 이해
클라우드 프로그래밍 모델 및 분산 처리 기술 습득
기타 클라우드/빅데이터 관련 기술 소개




과제는 eclass로 




Virtualization 실습
* Virtual machine/Container
Apache Hadoop 실습
* Container Environment
* HDFS
MapReduce IDE 실습
Apache Spark 실습
* Basic RDD Operations
* Spark-SQL
* Spark-Mllib
________________
Introduction
Big Data Definition
* So large or complex
* traditional data processing이 맞지 않다. (ex: RDBMS)
* 비정형 or 반정형
* 크다
* 21세기 원유
* 잘 정제하면 혁신
* 가치를 뽑아내는 능력
* 가공을 해야 가치가 생김(원유)




Data Deluge
* 데이터가 폭증
   * 2013 4.4 zettabytes
   * 2020 44 zettabytes
Source
* New york stock exchange
   * 4~5 terabytes per day
* Facebook
   * 7 petabytes per month
* Google
   * 20 PB per day
   * 20B web pages a day
      * 100+ PB for indexing
* LHC (Large Hadron Collider)
   * e-science
   * 30 petabytes per year
   * 1 petabyte of raw data per second
* 일개 컴퓨터가 저장할 용량이 아님


두 가지 문제:
* 어떻게 저장할 것인가?
* 어떻게 가공할 것인가?


데이터 분석 > 새로운 입자 발견
데이터 분석 > 장애 발생 징후 패턴 분석 > 고장 예측
데이터 분석 > 고객 패턴 분석 > 상업적 우월성 확보
데이터 분석(유전체) > 질병 징후 예측 > 맞춤형 헬스 케어
________________
Concepts of Big Data
* 규모
   * 기존 RDBMS의 수집 저장 관리 분석 역량을 넘어서는 데이터 (맥킨지)
   * 다양한 종류의 대규모 데이터로부터
      * 저렴한 비용으로 가치를 추출
      * 빠른 수집, 발굴, 분석
을 지원하도록 고안된 차세대 기술 및 아키텍처 (IDC)


Big Data & 3 Vs + 1
   * Volume
   * 데이터의 양
   * Big Data Architecture 선택에 영향을 주는 가장 중요한 요소
   * Velocity
   * 속도 (처리, 수집: 실시간)
   * Variety
   * 다양한 형태
   * (Value)
   * 데이터로부터 뽑아내는 가치


  

Text, PDF, Word + XML, JSON
Volume
   * 일반적으로 수십 테라 ~ 수십 페타
   * 기존 파일시스템은 물론 단일 저장소에 저장하기도 힘듦
   * Scalable(확장 가능)한 방식으로 데이터를 저장하고         분석
   * 분산 컴퓨팅(Distributed Computing)
   * Hadoop, Greenplum, Vertica, Netezza
   * Scale up: 컴퓨터 업그레이드
   * Scale out: 컴퓨터 추가 (분산 데이터)


중요한 데이터는 이미 RDB로 가공되어있음
Big Data는 가공되지 않은 비정형 데이터를 정형데이터로 추출하는 과정
Big Data는
   * 생성속도가 매우 빠르다
   * 비정형 & 반정형이다


Velocity
   * Real-time processing
   * 금융, 교통, 쇼핑, SNS
   * 데이터 생산, 저장, 유통, 수집, 분석의 실시간 처리가 중요
   * Batch processing
   * 수집된 대량의 데이터를 다양한 분석 기법과 표현 기술로 분석
   * 데이터마이닝, 기계학습, 자연어처리
Streaming Data
   * 실시간 건강 모니터링 정보
   * 실시간 교통 정보
   * 실시간 증권 정보
   * 실시간 ~


Variety
   * Structured
   * Form
   * RDBMS 쓰면 됨
   * Semi-Structured
   * XML, HTML, JSON
   * included Meta-data or Schema
   * Unstructured
   * 동영상, 사진, 메신저 내용, 오디오, 위치기록정보, 통화내용 등등


________________


Importance of Big Data
   * Cost reduction
   * big data technologies such as Hadoop and cloud-based analytics : 비용절감 도움
   * Faster, better decision making
   * with the speed of Hadoop in-memory analytics(Spark) : 속도
   * make decisions based on what they have learned
   * New products & services
   * 고객이 진정 원하는 서비스 개발로 연결




Definition of Cloud Computing
   * network of computers operating programs and applications
   * Virtual hosting solution




Concepts of Cloud Computing
   * As a Service
   * IaaS: Infrastructure as a service
   * H/W (Server, Storage, Network)
   * for IT departments
   * ex:
   * EC2(Elastic compute cloud)
   * S3(Simple storage service)
   * PaaS: Platform as a service
   * Platform (with API)
   * Platform에서 구동까지 포함하는 것이다.
   * Google Map API등은 PaaS라고 할 수 없다.
   * for Developers
   * ex:
   * Windows Azure
   * SQL Azure
   * .Net Service
   * SasS: Software as a service
   * Application on cloud
   * for YOU(범용적 사용자: personal user)
   * ex:
   * Google Apps
   * Office 365
   * SalesForce (B2B)
   1. On-demand self-service (필요한 만큼 직접 요청 사용)
   2. Resource pooling (적시 공급 가능)
   3. Broad network access (어디서든지)
   4. Rapid elasticity (Scalability rapidly)
   5. Measured service (측량 가능)


Utility Computing
   * What
   * pay as you go
   * dynamically provision
   * Why
   * Cost: capital vs operating expenses
   * Scalability: infinity
   * Elasticity: scale up or down on demand
   * Does it make sense?
   * benefits to cloud user
   * business case for cloud providers


Elasticity and Scalability
  

Utility computing은 사용량 만큼 대응되므로 의외로 시간, 비용 면에서 효율적이다.


Enabling Technology: Vertialization
  

Hypervisor
   * Type 2 hypervisor
   * Host operating system 위에 hypervisor를 올린 것
   * for Personal computer
   * Type 1 hypervisor
   * Hardware 위에 hypervisor를 올린 것
   * Bare Metal Hypervisor
   * for Server


________________


Container-based Virtualization
  

   * 각 Guest들은 Host operating system의 kernel을 공유한다.
   * 단점: 격리성이 적다. 호스트 운영체제와 필요 환경 운영체제가 동일해야 한다.
   * ex: Docker


Everything as a Service


Cloud Computing & Big Data
   * A source of problem
   * Cloud-based service generate big data
   * Cloud service will generate big data
   * Google apps Google photo like...
   * Clouds make it easier to start companies that generate big data
   * 즉 빅데이터 생산을 쉽게 만들어준다.
   * As well as a solution (Cloud can do)
   * ability to provision analytics cluster on-demand in the cloud
   * 필요에 따라 분석기능을 제공
   * commoditization(빅데이터를 흔하게 사용할 수 있는 기회를) and democratization(중소기업도) of big data capabilities
   * Why the Cloud and Big Data? Why Now?
   * https://www.datanami.com/2016/12/16/cloud-big-data-now/
   * Cloud Becomes Enterprise ready
   * 본래 중소기업을 대상으로 했음
   * 대기업은 보안이슈를 걱정했음
   * 안정성, 보안성이 검증 됨
   * Philips HealthSuite가 AWS Cloud-service를 사용함
   * Early adopters paved the way
   * Cloud에서 탄생하여 큰 성공을 거둔 기업들이 생김(선도기업)
   * Airbnb
   * Netflex
   * lyft
   * Enterprises are feeling the pain
   * Big data의 Scale up을 감당 못함
   * 관리 자체가 큰 부담
   * cloud service can do
   * remove management burden
   * can apply cutting edge(최신기술)
   * 대기업들이 골치아픈 대규모 Infrastructure 관리가 아닌 진정 원하는 도전에 집중하게 할 수 있다.


그러니까 클라우드컴퓨팅과 빅데이터는 뗄 수 없는 관계






________________


Tackling Big Data
빅데이터를 어떻게 다룰 것인가?
Divide and conquer
  

   * Big data
   * Big compute


Parallelization Challenges
병렬처리는 그렇게 단순한 문제가 아니다.
   * 어떻게 여러개의 worker에 작업을 분배해줄것인가?
   * Worker보다 작업이 많을 경우 어떻게 분배를 최적화 할 것인가?
   * Worker들이 서로 중간 결과물을 공유해야 한다면?
   * 중간 결과물을 aggregate(합칠) 것인가?
   * 모든 worker의 실행이 끝났음을 알 것인가?
   * Worker가 중간에 죽어버리면?


   * Parallelization problems arise from:
   * Worker간 통신
   * 공유된 데이터
   * Synchronization mechanism이 필요하다.


   * Concurrency(동시성, 병렬성) is difficult to reason about
   * Concurrency is even more difficult reason about
   * datacenter level 또는 datacenter들을 노드로 사용하는  scale
   * in the presence of failures(실패가 있는 상황)
   * in terms of multiple interacting services
   * 여러 상호작용하는 서비스들이 맞물림
   * Not to mention debugging…
   * 디버깅 하기 힘듦
   * The reality
   * lots of one-off solutions, custom code (한 번 쓰고 버리는 코드)
   * write your own dedicated library, then program with it
   * burden on the programmer to explicitly manage everything
   * 그러니까 현실적으로 Parallelization은 프로그래머가 죽어나간다는 거임.


Programming Models and Design Patterns
   * Programming models
   * Shared memory (pthreads)
  
      * Scale-up 방식 밖에 안된다(Single machine)
      * Message passing (MPI)
  
         * Scale-out 방식도 가능하다(Multiple machines)
         * Design Patterns
         * Master-slaves
  
            * 가장 구현이 쉬움
            * Producer-consumer flows
  
               * 작업 생성자가 있고
               * consumer는 자기에게 관심 있는 작업이 나오면 수행한다.
               * Shared work queues
  




Making the datacenter as a computer
우리의 목표
                  * Right level of abstraction
                  * moving beyond the Von Neumann architecture
                  * 하나의 거대한 폰노이만 아키텍쳐
                  * Instruction set for Datacenter computer
                  * Hide system-level details
                  * Hide race conditions, lock, contention[a], etc.
                  * No need to explicitly worry about reliability, fault tolerance, etc.
                  * Separating the what from the how
                  * 개발자가 이러한 이러한 데이터처리를 하고 싶다 명시(what)하면
                  * 알아서(how) framework(runtime)가 처리한다.
                  * non-procedural language의 철학(SQL)
                  * How는 procedural language
Big Ideas
                  * Scale out, not up
                  * SMP는 limitation이 크다
                  * Move processing close to the data
                  * cluster는 한정된 bandwidth를 지니고 있다.
                  * Process data sequentially, avoid random access
                  * 탐색은 비싼 작업
                  * Disk throughput이 큰 이유
                  * Seamless scalability
                  * simply adding more servers
Scaling up vs. out
                  * 16 * 128-core single machine vs. 128 * 16-core machine
                  * 후자가 전자보다 압도적으로 싸다.
                  * 후자는 commodity machine으로 처리 가능하지만 Large SMP는 맞춤설계품
                  * Nodes need to talk to each other
                  * intra-node latencies: ~100ns (SMP)
                  * inter-node latencies: ~100us
                  * communication cost가 증가함


Storage Hierarchy
  

                  * 위로 갈 수록 throughput은 좋아짐
                  * 아래로 갈 수록 용량이 증가함


  

                  * Latency는 장비의 성능
                  * Bandwidth는 통신의 성능
                  * Capacity는 장비와 규모에 따라 성능차가 생김


Seeks vs. Scans
                  * Consider a 1 TB database with 100 byte records(tuples)
                  * Scenario 1: random access
                  * Each update: ~30 ms(ssek, read, write)
                  * 108 updates = ~35 days
                  * Scenario 2: rewrite all records
                  * 100 MB/s throughput, only one seek
                  * time = 5.6 hours
                  * 전체를 다시 쓰는게 record 업데이트보다 빠름.
                  * Avoid random seeks!




Justifying the Big Ideas
                  * Scale out, not up
                  * Move processing close to the data
                  * not move data to processing
                  * Process data Sequentially
                  * Seamless scalability
                  * 이걸 해결한 솔루션 중 하나가 Hadoop




Hadoop Platform for Big Data
Basic concepts of Hadoop
Why Hadoop?
Big Data & Hadoop
                  * De facto standard (사실상의 표준)
                  * Big data store platform
                  * Big data processing platform
                  * https://hadoop.apache.org


History of Hadoop
                  * Nutch platform: Doug Cutting
                  * Google publishes GFS & MapReduce papers
                  * GFS: SOSP’ 2003
                  * Sanjay Ghemawat, Howard Gobioff, Shun-Tak Leung
                  * MapReduce: OSDI’ 2004
                  * Jeffrey Dean, Sanjay Ghemawat
                  * add DFS + MapReduce implementation to Nutch
                  * Yahoo! hire Cutting
                  * Hadoop spins out of Nutch
                  * NY Times use image archives over 100 EC2s
                  * Facebook launches Hive: SQL support for Hadoop
                  * Yahoo! Fastest sort of a TB, 3.5mins over 910 nodes
                  * Cloudera Founded launched
                  * Fastest sort of a TB, 62 secs over 1,460 nodes sorted a PB in 16.25 hours over 3,658 nodes
                  * Hadoop summit 2009, 750 attendees
                  * Doug cutting join Cloudera


                  * The Google File System (GFS)
                  * Hadoop HDFS: Store (분산저장소)
                  * MapReduce: Simplified data processing on large cluster
                  * Hadoop MapReduce: Processing (분산처리)


Why Hadoop?
Hadoop?
                  * 대용량 데이터를 분산 처리할 수 있는 Java기반 오픈소스 프레임워크
                  * Google의 GFS, MapReduce를 구현한 결과물
                  * 오픈소스 검색엔진 Nutch로 시작
                  * 2008년 Apache 최상위 프로젝트로 승격
                  * HDFS(Hadoop Distributed File System)에 데이터를 저장하고
                  * 분산처리시스템 MapReduce로 데이터를 처리




Why?
                  * 엄청나게 많고 다양한 종류의 데이터(Variety, Volume)
                  * 정형 데이터 > RDBMS (사용 불가)
                  * 비정형 데이터 > ?? (비용, 크기 문제)
                  * Hadoop의 장점
                  * Open source : License비용 적다(vs. Commercial RDBMS)
                  * Commodity Hardware: 상용 하드웨어 사용 가능
                  * 범용적인
                  * x86 CPU + Linux
                  * Scale-out 아키텍처
                  * 데이터 복제: 유실, 장애 대응 가능
                  * Data Locality
                  * 데이터를 여러 서버에 분산 저장
                  * 데이터가 저장된 각 서버에서 동시에 데이터를 처리
                  * Processing을 Data에 가깝게 Moving


Misunderstanding about Hadoop
                  * RDBMS를 대체하지는 않는다.
  
                     * Hadoop과 RDBMS는 상호보완적
                     * ETL(Extraction, Transformation, Loading)과정의 효율적인 구현
                     * Extraction: 필요한 데이터를 추출
                     * Transformation: 변환
                     * Loading: Data warehouse or Data mart에 전송과 로딩
                     * 신속한 데이터 처리, 즉 트랜잭션이 매우 중요한 데이터를 처리하는데 Hadoop은 부적합하다.
                     * Hadoop은 NoSQL이 아니다(구성 요소 중 하나로 지원할 뿐).
                     * Hadoop platform의 구성 요소 중 하나 HBase를 통해 NoSQL을 제공
                     * NoSQL(Not-only-SQL)
                     * RDBMS가 분산 환경에 적합하지 않음
                     * RDBMS는 Scaling-up 방식
                     * Key-Value Pair로 구성
                     * Index, Data가 분리되어 운영
                     * Join이 없음, RDBMS의 Raw로 존재하던 데이터들을 하나의 집합된 형태로 저장
                     * Sharding기능: 여러 서버에 나누어 저장
                     * RDBMS의 데이터 무결성과 정합성을 제공하지 않음
                     * MongoDB, HBase, CouchDB, Cassandra, Redis…


Hadoop’s Problems
                     * 고가용성(HA: High Availability) 지원
                     * 99.999%의 가용
                     * 1년 중 30분 정도를 제외하고 항상 사용 가능
                     * Name Node(HDFS)의 중앙 집중적인 메타데이터 관리(Master-Slaves)
                     * Single point of failure & contention
                     * Master가 나가면 망함
                     * Master의 overhead가 심함
                     * 2013 2.0 정식 버전부터 고가용성 지원
                     * File Namespace 제한
                     * Name Node가 관리하는 메타데이터는 메모리로 관리
                     * Name node가 마스터
                     * Memory 용량이 HDFS에 저장되는 파일과 디렉토리 개수를 제한한다.
                     * 데이터 수정 불가
                     * 한번 저장된 파일은 수정 불가
                     * Move, Rename은 가능
                     * 내용 수정은 불가
                     * Append는 가능함
                     * Hadoop은 Reading, Batch processing에 적합
                     * Big Data의 특성
                     * Archive
                     * Analytics
                     * 기존 데이터를 Update는 하지 않는다.
                     * POSIX 명령어 미지원
                     * rm, mv 등의 POSIX 형식 파일 명령어 사용 불가
                     * Hadoop은 별도의 Shell command / API를 활용
                     * 전문 업체 부족
                     * 국내는 하둡과 관련된 다양한 전문 업체가 부족
                     * Oracle, MS-SQL같은 상용 DBMS는 다양한 벤더, 유지보수 업체 보유
                     * IBM, HP같은 다양한 외산 벤더들이 각자의 Hadoop Solution을 선보이나,
                     * Amazon, Facebook, Yahoo와 같은 인터넷 업체에 비해 부족
                     * 자체적인 기술력과 노하우 확보 전략 필요


Major Hadoop Distribution
                     * Cloudera(클라우데라)
                     * CDH(Cloudera’s Distribution for Apache Hadoop)
                     * 특징
                     * 대부분의 Hadoop Echo system 포함
                     * 일부 기능 및 버그패치를 CDH에 먼저 적용
                     * MapReduce framework 별도 제공(YARN 비 통합 버전)
                     * HUE 관리툴로 관리
                     * Cloudera Manager로 CDH 쉽게 설치
                     * Hortonworks(호튼웍스)
                     * HDP(Hortonworks Data Platform)
                     * 특징
                     * 철저하게 Apache 배포판 중심
                     * Apache 원본 그대로
                     * Ambari를 이용해 관리
                     * MapR Technologies
                     * MapR Editions
                     * 특징
                     * Hadoop C/C++로 구현체
                     * HDFS를 자사 플랫폼으로 대체
                     * MapReduce, Hbase, Pig, Hive, Mahout등을 지원
                     * Cloudera + Hortonworks 합병
                     * Hewlett packard enterprise + MapR Tech. 합병
                     * 왜 안 되었나?
                     * Google, Amazon 등의 Cloud service가 알아서 해줌.
                     * 굳이 직접 운용할 이유가 없어지고 있다.




Hadoop Echo system
  

________________


Principles of Cloud Computing
Basic concepts & features of cloud computing
Cloud computing in a Nutshell
                     * When plugging an electric appliance into an outlet...
                     * we can nether how electric power is generated nor how it gets to that outlet
                     * electricity is virtualized:
                     * hide
                     * power generation system
                     * huge distribution grid
                     * show
                     * 전기, 물, 가스, 통신, 기타 등등 utilities
                     * When extends to information technologies
                     * 유용한 기능들을 제공하지만, 어떻게 동작하는지는 숨겨짐.
                     * fully virtualized:
                     *  computing에 필요한 자원
                     * processing, storage, data, software resource
가 제공되어야 한다.
                     * saas iaas paas는 내부적으로 뭔가 복잡한 구조가 있지만 감추어져 있다.
                     * 대용량의 컴퓨팅 리소스를 가상화 하여 제공한다.
                     * cluster(local area), grid(group of cluster), cloud computing(world wide)
                     * aggregating resources and offering a single system view
                     * delivering computing as a utility
                     * Utility Computing (business model)
                     * on-demand delivery of computing power
                     * pay-as-you-go
                     * 공공 utility서비스와 비슷하다.
                     * Cloud-computing은 utility computing을 구현한 것
                     * Cloud computing = 범용적 단어가 됨
                     * sophisticated on-demand computing services
                     * Commercial providers
                     * Amazon
                     * Google
                     * Microsoft
                     * 어딘가(cloud)에 있는 집합: 개인, 회사가 전 세계 어디에서든(anywhere) 필요(on demand)에 따라 접속 가능
                     * as a service: computing, storage , software가 as a service 로 제공된다.
                     * 주요 특징
                     * pay-per-use
                     * elastic capacity
                     * illusion of infinite resources
                     * 무한한 것처럼 보임
                     * self-service interface
                     * 알아서 필요한 만큼 스스로 요청하고 조정함
                     * abstracted or virtualized resources
                     * 자원들의 추상화
                     * Cloud는 raw computing & storage만 의미하지 않는다
                     * software, services, APIs & development tools
                     * Run their everyday IT infrastructure “in the cloud”
                     * 모든 IT infrastructure를 cloud 내에 포함하는걸 궁극적인 목적으로 함
                     * computing resource delivering을 utility처럼 해 내는 것은 오랜 꿈이었음
                     * 여러 선행기술들이 있었음


Root of Cloud computing
  

                     * 다양한 분야에서 기술들이 발전 결합되어 나온 결과물이 cloud computing
                     * Minframes to Cloud
                     * in-house generated computing power > utility-supplied computing resources
                     * 100년전에 일어난 현상
                     * factory
                     * in-house generator > utility supplied electric power
                     * 직접 생산하는 것 보다 유틸리티로 제공받는 것이 더 싸다
                     * Benefits to Consumers
                     * reduction on IT-related costs
                     * choosing cheaper services from external providers
                     * 비싼 전문 인력 고용을 피할 수 있음
                     * on-demand
                     * adapt their IT usage
                     * rapidly increasing or unpredictable computing needs
                     * 필요량에 따라 즉각즉각 Scaling
                     * unpredictable: 예측할 수 없는
                     * Benefits to IT services Providers
                     * 어차피 데이터센터 운영중
                     * 추가적인 이득을 얻음
                     * Return on investment(ROI): 손익분기점에 빨리 도달함
                     * Total cost of ownership (TCO): 운영비 절감효과
                     * Key enablers of computing delivered as a utility
                     * often underutilized: 현대 조직의 컴퓨터 자원들은 제대로 활용되고 있지 않음. (항상 켜놓지도, 항상 100 로드중이지도 않다: amazon이 cloud-computing 서비스에 뛰어든 이유)
                     * 광통신 케이블 등 네트워크 발전이 있었음.
                     * delivering computing services의 speed, reliability가 local machine처럼 변함
                     * SOA, Web services, Web 2.0, Mashups
                     * Web Services (WS): software integration
                     * glue together applications running on different messaging product platforms
                     * information을 타 플랫폼 타 애플리케이션 에서도 활용 가능한 길이 열림
                     * WS software stack has been specified and standardized
                     * HTTP, XML, etc… (ubiquitous technologies)
                     * Service-Oriented Architecture (SOA)
                     * 서비스들을 엮어서 큰 시스템을 만들 수 있음
                     * Service에 기반한 아키텍처
                     * loosely-coupled: 느슨하게 연결된 분산 컴퓨팅
                     * In a SOA, software resources are packaged as “services”
                     * modules
                     * well-defined
                     * self-contained
                     * 엮어서 큰 시스템을 만들 수 있음
                     * b2b
                     * Software as a Service(SaaS) domain
                     * 제공자가 서로 다르다 하더라도 하나의 서비스로 만들 수 있음
                     * authentication, e-mail, payroll management, calendars등을 building block으로 사용하여 큰 서비스를 제작할 수 있음.
                     * Grid Computing
                     * 분산된(distributed) 자원을 묶어서(aggregation) 투명하게(transparently) 접근할 수 있음
                     * compute, storage 자원을 조직을 넘어 공유한다
                     * 서로 다른 대학들이 공유한다던가
                     * speeding up a board range of scientific applications
                     * 과학응용분야
                     * climate modeling, drug design, protein analysis
                     * 미국에서 탄생, 유럽에서 잘 활용됨
                     * Web services-based protocols
                     * discovered, accessed, allocated, monitored, accounted
                     * 문제점
                     * QoS(Quality-of-Service) 보장이 어려움
                     * lack of performance isolation
                     * 헤비유저에게 영향을 많이 받음
                     * 성능이 오락가락
                     * time-critical한 작업에 맞지 않음
                     * portability barrier
                     * 실행환경이 원체 다양함.
                     * 동일한 환경제공이 어려움
                     * operating system, libraries, compilers, runtime environments, etc.
                     * utility computing으로 발전할 수 없었음.
                     * 과학적 가치는 있었지만 상업적 가치는 부족했음
                     * Hardware Virtualization
                     * Grid computing의 performance isolation, portability barrier를 극복함
                     * allow multiple operating systems, software stacks on single physical platform
                     * Hardware virtualization
  
                     * 어떻게 등장할 수 있었나?
                        * Multicore chip
                        * paravirtualization: 반가상화
                        * hardware-assisted virtualization: 하드웨어에서 가상화 지원
                        * live migration of VMs: 가상머신 실행되는 도중에 물리적으로 하드웨어들을 옮겨가거나 성능을 조절할 수 있음
                        * Isolation, Consolidation, Migration
                        * Isolation
                        * Workload isolation
                        * 모든 프로그램 실행을 가상머신 안에 가둘 수 있다.
                        * improvements in security
                        * better reliability
                        * 하나 죽어도 다른건 멀쩡함
                        * 하나의 가상머신의 오버로드가 다른 가상머신에 영향을 안 준다.
                        * Consolidation
                        * 여러개의 이기종 workload를 하나의 physical platform에 통합 가능하므로
                        * 시스템 활용도(system utilization)가 좋아짐
                        * 하드웨어 업그레이드가 용이해짐
                        * incompatibility 문제가 낮아짐
                        * legacy와 new operation system이 같이 돌 수 있음
                        * Migration
                        * workload migration
                        * 디스크에 저장해서 다른 플랫폼으로 이동
                        * live migration
                        * 멈추지 않고 다른 플랫폼으로 이동
                        * load balancing, maintenance, disaster recovery
                        * Autonomic Computing
                        * 컴퓨팅 시스템의 복잡성 증가 해결을 목적으로 함
                        * 사람이 개입해야할 일을 줄인다.
                        * 사람에게 high-level 가이드를 제공해야 한다.
                        * 즉, 어느정도 자율 관리가 되는 시스템
                        * rely on
                        * monitoring probes and gauges(sensor)
                        * 모니터링 데이터 기반 최적화를 수행하는 적응형 엔진(autonomic manager)
                        * 시스템 변경을 수행할 수 있는 effector들
                        * 거대한 데이터센터를 운용하는 Cloud computing provider에게 중요한 부분
                        * 관리 비용 절감
                        * data center automation으로 확장됨
                        * service levels of running applications
                        * 고가용성
                        * 응답시간
                        * 계약에 명시된 품질 이하로 떨어지면 보상해야 함
                        * 대개는 시스템 down time 기준
                        * 개량화가 가장 쉽다.
                        * data center capacity
                        * proactive disaster recovery
                        * automation of VM provisioning


Layers and Types of Clouds
  



Netflix등도 SaaS라고 할 수 도 있을 것임 (Cloud applications)


                        * Infrastructure as a Service
                        * virtualized resources
                        * computation, storage, communication
                        * Cloud infrastructure
                        * on demand 형태로 server를 provisioning 하는 것이다.
                        * 다양한 OS
                        * customized된 software stack을 담을 수 있다.
                        * eg: Amazon Web Service (AWS)
                        * EC2 : VM
                        * 쉽게 customized 될 수 있다.
                        * software stack
                        * 사용자에게 다양한 활동을 할 수 있는 privilege(권한)들을 제공한다.
                        * Platform as a Service
                        * Programmable한 higher level abstraction
                        * Cloud platform
                        * 다음을 관여할 필요가 없음
                        * processing
                        * memory
                        * 새 애플리케이션 개발에 multiple programming models and specialized services(data access, authentication, payments) are offered as building block들로 제공
                        * eg: Google AppEngine
                        * building blocks 
                        * include an in-memory object cache (memcache), 
                        * mail service, instant messaging service (XMPP), 
                        * an image manipulation service, 
                        * and integration with Google Accounts authentication service
                        * Software as a Service
                        * 일반 사용자들, 혹은 기업 사원들이 사용할 수 있는 Application들이다.
                        * google cloud
                        * google docs 등…
                        * 서비스 사용자 입장: software 관리 비용이 사라짐
                        * 서비스 제공자 입장: 개발 & 테스트가 단순화 됨
                        * web browser에서 동작하면 됨.
                        * 사용자의 다양한 컴퓨팅 환경을 걱정 안 해도 됨.
                        * cross platform 등의 문제가 사라짐.
                        * eg: Salesforce.com
Deployment Models
                        * Public / Internet Cloud
                        * 돈만 내면 누구나 사용 가능
                        * pay as you go: available on subscription basis
                        * 3rd party가 multi-tenant Cloud infrastructure & services
                        * multi-tenant: 다양한 기업들이 사용할 수 있는
                        * Private / Enterprise Cloud
                        * Company’s own Data Center / infrastructure for internal and / or partners use.
                        * 한 회사 내에서 동작하는 intranet에 구축되는 cloud service
                        * 아무나 접근 못함.
                        * 회사 구성원에게 필요한 만큼 할당하여 사용한다.
                        * 회사의 infrastructure를 가상화 기술, cloud-like 인터페이스를 더하여 재구성 하는 것
                        * 가상화 기술
                        * 비싸고 거대한 회사 자원들을 효율적으로 활용하기 위한 발악
                        * 이를 통해 비싼 자원(슈퍼컴퓨터 같은)을 보호할 수 있음
                        * privileged access
                        * per-usage metering
                        * Community cloud
                        * shared by several organizations and supports a specific community that has shared concerns
                        * 여러 조직에서 공유하고 관심사를 공유하는 특정 커뮤니티를 위한 cloud
                        * Hybrid / Mixed Cloud
                        * Private cloud가 제공하는 자원이 충분치 않으면
                        * 민감한 것은 private cloud에 / 그렇지 않은 업무는 public cloud로
                        * Cost를 절감할 수 있음.
                        * Cloud-bursting: Private 자원이 부족할 때 필요에 따라 public cloud 제공자로부터 빌려쓸 수도 있음.
                        * 가장 인기있는 모델


Desired Features of the Cloud
목표로 하는 기능들
                        * Self-service
                        * 서비스 사용자가 알아서 원하는 만큼 요청하여 구성하고 사용할 수 있음
                        * 이 과정에서 서비스제공자 측이 따로 뭔가 해줄 필요 없이 자동화 되어야 함.
                        * Per-usage Metering and Billing
                        * 사용한 만큼 과금 되어야 함.
                        * 초창기 고비용의 투자 요구사항이 사라짐
                        * 딱 필요한 만큼 투자하면 된다.
                        * Short-term basis (e.g. by the hour, by the second)
                        * 사용자는 더이상 필요하지 않은 자원을 바로 해제 가능함
                        * 사용량의 정량화 된 과금 체계는 사용자는 서비스의 가격 경쟁력을 비교해볼 수(trading) 있다
                        * Elasticity
                        * 필요에 따라 빠르게 늘였다 줄였다
                        * 마치 필요하다면 무한한 자원이 제공되는 거 같음
                        * 어떤 응용에선 Auto scaling이 가능하기도 함(보통 scale-out)
                        * application load가 증가하면 자동으로 추가 자원 할당 (add node)
                        * application load가 감소하면 자동으로 유휴 자원 반환 (release node)
                        * Customization
                        * 여러 다양한 군집(multi-tenant)들에게 제공하기 위해 최대한 customization이 가능하게 만들어야 한다.
                        * IaaS의 경우는 쉽다.
                        * PaaS나 SaaS는 힘들다.
                        * abstraction level이 올라갈 수록 이런 맞춤화 기능 제공은 어려워짐


The Future of a Data Center?
  

                        * Disaggregated Data Center
                        * 데이터센터를 분산시킨다.
                        * 현재는 서버 단위로 묶여있음.
                        * 이것을 component단위로 분해한다.
                        * AWS 같은 IaaS나 PaaS들을 가지고 node단위를 component삼아 하나의 거대한 컴퓨팅 시스템으로 만들 수 있을까?
                        * 사용량에 따라 scalability가 쉬워질 것이고
                        * 장애에 대한 내구성도 오를 것이다.
                        * Processing만 제공하는 node
                        * GPU만 제공하는 node
                        * TPU만 제공하는 node
                        * Storage만 제공하는 node
                        * …
Summary
                        * Cloud computing = 새로운 컴퓨팅 패러다임
                        * 개인, 대기업에게 원하는 만큼 제공하고 그 만큼 과금하는 것
                        * 여러 기반들이 쌓여 Evolution 식으로 구현 되었다.
                        * 아마도 Amazon같은 대기업의 시도가 큰 역할을 했을 것
                        * As a Service
                        * 여러 compute, storage, network, software 혹은 combination들을 as a service로 제공하는 것
                        * Infrastructure ~
                        * Platform ~
                        * Software-as-a-service


Virtualization Technologies
https://spri.kr/download/22084


Elasticity and Scalability of Cloud
  

                        * Elasticity: 탄력성 (늘렸다 줄였다)
                        * Scalability: 확장성 (늘리는 측면)
                        * 실제 요구하는 자원은 변동이 심함.
                        * 기존 on-premises capacity는 대개 정해진 양을 처음부터 구축하게 됨으로 널널할 때는 낭비되고 많이 필요할 때는 부족하게 된다.


Cloud Enabling Technology: Virtualization
                        * Virtualization은 Cloud를 위해 태어난 것은 아니지만 Cloud에서 가장 잘 활용되는 핵심 기술이 됨
                        * Hypervisor
                        * Physical Machine 위에 마치 독립된 machine처럼 동작하는 Virtual Machine이 배치됨
                        * Hardware로부터 추상화를 제공하는 프로그램
                        * Types
                        * Type 1(Bare-metal): Host OS 없이 Hypervisor가 바로 올라감
  
                           * 주로 서버
                           * 대개 사용자와 거리가 멀어 GUI interaction interface를 요구하지 않는다.
                           * 장치가 보통 단순하고 표준화 되어있다.
                           * Hypervisor가 직접 다루기 용이
                           * Type 2: Host OS 위에 응용프로그램으로서 Hypervisor가 올라감
  
                              * 개인 데스크탑, 노트북
                              * 장치가 다양하다
                              * 환경이 너무 다양하여 Hypervisor가 직접 다루기 힘들다.
                              * Host OS의 지원이 있으면 편함
                              * Container  Based Virtualization
  
                                 * Guest OS가 없다.
                                 * Container Engine이 Host OS위에 배치
                                 * 운영체제는 Host OS에 전적으로 의존
                                 * Host OS의 Kernel에 의존
                                 * 해당 기능은 Linux Kernel의 기능
                                 * 각각 Guest가 host OS의 process처럼 동작한다.
                                 * 어느정도 독립적 환경을 제공하지만 완전히 구분된 머신은 아님
                                 * 장점
                                 * 이미지가 작다
                                 * 부팅시간이 빠르다
                                 * 가볍다(VM OS가 없음)
                                 * 런타임 환경 패키징이 편함 = 배포도 편함
Basic Concepts of Virtualization
                                 * 물리적 컴퓨터 자원을 추상화
                                 * HW를 논리적 객체로 추상화
                                 * Partitioning: 하나의 장치를 여러개처럼 동작시킨다. (대중적)
  
                                 * Aggregation: 여러개의 장치를 묶어서 하나의 장치처럼 동작시킨다.
  
                                    * 프로그램의 구현이 쉬워진다.
                                    * 거대한 메모리가 필요할 때
                                    * 거대한 프로세서풀이 필요할 때
                                    * 클라우드 컴퓨팅 구현을 위한 핵심기술
                                    * CPU, Memory, Storage, Network 등
                                    * 서버나 장치들을 가상화 함으로 높은 수준의 자원 사용율, 분산처리 능력 제공
                                    * 데이터 센터의 효율적인 자원 관리
                                    * 서비스 사업자의 서버에서 제공되는 서비스는 항상 많은 양의 컴퓨팅 자원을 소모하지 않음
                                    * 어디서는 넘쳐나고, 어디서는 부족함
                                    * 평균적으로는 10~15% 사용
                                    * 하나의 서버에 동시에 여러 운영체제 가동, 캄퓨팅 자원이 모자란 서버의 요청 테스크를 분산처리 가능
                                    * 사용률을 70%까지 끌어올릴 수 있음
                                    * 서비스 로드벨런싱이 가능해짐
                                    * 클라우드 컴퓨팅
  
                                       * Virtualization으로 여러 자원들을 하나로 통합하여 제공
                                       * History
  
                                          * 1960s IBM Mainframe
                                          * 2001 VMWare (x86 virtualization)
                                          * 2003 Citrix Xen Open Source solution
                                          * 효과
                                          * 비용절감
                                          * HW구매, 유지 * 보수 비용 감소
                                          * 추가적인 서버 증설 요구 감소
                                          * 서버 개수 종류 단순화
                                          * 서버 감소로 절전효과, 공간 효율성, 냉각 효율성
                                          * 서비스 개발 용이성 & 운영의 유연성
                                          * 다양한 환경에서 동작하는 코드를 하나의 워크스테이션에서 개발가능
                                          * 리눅스, 윈도즈, verity environments
                                          * 서비스의
                                          * 통합(Clustering)
                                          * 분할(Partitioning)
                                          * 이동(Migration)
                                          * 업무량(Workload)
등의 비즈니스 요구에 유연하게 대처 가능 
Types of Virtualization
                                             * 서버 가상화, 데스크톱 가상화(VDI), 애플리케이션 가상화
                                             * Server Virtualization
  
                                                * Hypervisor - Virtual Machine
                                                * Virtual Desktop Infrastructure
  
                                                   * 물리적으로 존재하지 않는 가상의 개별 컴퓨터
                                                   * 모니터, 스피커, 마우스, 키보드 등의 필수적인 입출력 장치만 활용하거나 매우 단순화된 인터페이스만 가지고 컴퓨터를 활용
                                                   * 가상의 데스크톱을 마치 로컬 시스템처럼 활용 가능
                                                   * 모든 작업은 센터에 위치한 서버에서 이루어짐
                                                   * 장점
                                                   * 보통의 PC 보다 5~10% 전력소모
                                                   * 데이터가 서버에 있음 PC의 복원, 생성 용이
                                                   * 직접 구매해서 설치할 필요도 고칠 필요도 없다.
                                                   * 보안
                                                   * 데이터 센터 급 보안 서비스 보장
                                                   * 모니터링, 캡슐화
                                                   * 관리
                                                   * 적은 종류의 가상 PC 이미지로 다수의 가상 PC 생성 가능
                                                   * 일괄 업데이트 용이
                                                   * Application Virtualization
  
                                                      * VDI와 차이점은
                                                      * VDI는 화면(입출력)만 땡겨옴
                                                      * 네트워크 필수
                                                      * 서버 인프라 구축 필요
                                                      * Application Virtualization은 클라이언트에서 실행
                                                      * 로컬 실행 (로컬 자원 사용)
                                                      * 오프라인 이용 가능
                                                      * 배포만 되면 서버 인프라는 필요 없음
Hypervisor-based Virtualization
                                                      * Virtual Machine (VM)
                                                      * 가상화를 통하여 구현되는 복제된 컴퓨팅 환경
                                                      * 물리적 컴퓨터와 동일한 수준의 실행기능을 제공하는 것을 목적
                                                      * 가상머신들 간 물리적인 하드웨어를 공유
                                                      * 내부구조는 물리적인 서버의 컴퓨팅 환경과 유사
                                                      * CPU, Memory, Storage 존재
                                                      * 여러개의 가상머신이 하나의 물리 서버에 동시에 존재
                                                      * 각 가상머신마다 서로 다른 구동 환경을 갗출 수 있음
                                                      * 다양한 애플리케이션을 실행하는 것이 가능
                                                      * 리눅스용 앱
                                                      * 윈도즈 앱
                                                      * 안드로이드 앱
                                                      * 등을 동시 가능
                                                      * Consolidation(통합)이 가능하다
                                                      * 여러 하드웨어 자원에 접근 가능
                                                      * 가상머신 관점:
                                                      * Guest OS는 하드웨어 디바이스가 가상이라는 것을 알지 못 함
                                                      * 표준 디바이스처럼 작동
                                                      * Paravirtualization
                                                      * Guest OS가 하드웨어 가상화를 인지
                                                      * Performance측면 때문에 생긴 기능
                                                      * Isolation 보장 : 분할 된 시스템 간 상호 간섭이 없음
                                                      * GRID Computing의 가장 큰 단점이 해결됨
                                                      * Hypervisor
                                                      * H/W가상화를 위해
                                                      * VMM(Virtual Machine Monitor) : 중간 관리자
                                                      * H/W의 물리적 리소스를 VM들에게 제공
                                                      * VM과 H/W간의 I/O 명령 처리
                                                      * 3가지 요구 요소
                                                      * Fidelity(정확성)
                                                      * 물리머신과 동일해야함
                                                      * Isolation(독립성) & Safety(안정성)
                                                      * Hypervisor는 시스템 자원에 대한 완전한 제어권을 보유
                                                      * 특정 가상머신이 죽는다고 다른 가상머신이 죽지 않음
                                                      * Performance(성능)
                                                      * VM과 물리적 환경간의 성능차가 없어야 함
                                                      * 사실 불가능하다(어디까지나 목표)
가상머신은 성능 때문에 쓰는 것은 아님(partitioning)
                                                         * Types
                                                         * Type1 (Bare-metal)
                                                         * 하드웨어 위에서 바로 구동
                                                         * Guest OS는 H/W 위에서 2번째 수준으로 구동
                                                         * 여러 H/W 드라이버를 세팅해줘야 한다. 설치가 어렵다.
                                                         * 지원되는 하드웨어가 한정될 가능성이 높음
                                                         * Type2
                                                         * Host OS 위에서 구동
                                                         * Guest OS는 H/W 위에서 3번째 수준으로 구동
                                                         * 기존 컴퓨터 환경에서 활용하기 때문에 설치가 용이하고 구성이 편리하다
                                                         * Type1 보다는 성능이 떨어짐
                                                         * Full Virtualization vs. Paravirtualization
  
                                                            * I/O에 대한 접근을 어디까지 가상화 할 것인가?
                                                            * 전가상화
                                                            * VMM이 Host OS를 통해 하드웨어에 접근한다. (Intel VT, AMD V)
                                                            * Guest OS > CPU VT > Host OS > H/W
                                                            * 반가상화
                                                            * Citrix Xen Hypervisor가 예 [영국]
                                                            * Host OS는 하드웨어 Driver를 관리하고 있음.
                                                            * Guest OS는 가상화 환경을 인지하고 활용할 수 있게끔 수정되어있다. (특정 protocol 제공)
                                                            * 전가상화의 Host OS에 몰리는 I/O Bottleneck을 해결하기 위함
                                                            * Performance 향상
  

                                                            * Virtualization의 계보
                                                            * Operating System virtualization은 Docker같은 컨테이너를 뜻함
                                                            * 처음엔 Software Assisted로 구현됨
                                                            * Hosted만 가능했음.
                                                            * 성능을 위해 Hardware Assisted가 개발됨
                                                            * Bare-metal 방식이 가능해짐(type1)
                                                            * Full Virtualization
                                                            * 하드웨어 리스소를 완전히 가상화
                                                            * Guest OS 수정 없이 사용 가능
                                                            * Guest OS는 가상화 여부를 알 수 없다.
                                                            * CPU의 가상화 지원 기술과 같은 하드웨어 기능을 일부 지원받을 수 있다.
                                                            * VT, Virtualization Technology
                                                            * Intel-VT
                                                            * AMD-V
                                                            * SR-IOV?
                                                            * Intel’s vt-d/x/i, AMD’s pacifica
                                                            * PCI pass-thru (I/O virtualization)
                                                            * VNIC supports ~Gbps performance
                                                            * TYPE-2: Guest OS는 기존의 OS를 통해서 하드웨어 접근
                                                            * Guest OS의 H/W 접근 / 제어는 CPU의 VT가 Hypervisor에게 H/W접근을 요청하게끔 Translation한다.
                                                            * 처리단계가 늘어남 = Hypervisor의 부담 가중
                                                            * 성능이 반가상화보다 안 좋다.
                                                            * VMware ESX Server. Microsoft Hyper-V 등
                                                            * Paravirtualization
https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=bycho211&logNo=220706893884
                                                               * 하드웨어를 완전히 가상화하지 않음
                                                               * Citrix Xen
                                                               * 논문으로 시작
                                                               * Guest OS의 수정이 필요
                                                               * PV[b]: 대개 Linux같은 open source만 가능
                                                               * HVM[c]: windows등의 수정되지 않은 OS가 설치될 수는 있더라도 hypercall 등의 paravirtualization의 핵심 기능을 사용하지는 못 함.
이 경우 VM은 full virtualization으로 돌게 된다.
                                                                  * Guest는 자신이 virtualization된 환경에서 돌고 있음을 인지해야 한다.
                                                                  * I/O 접근을 Hypercall을 수행해야 함
                                                                  * Hypercall
                                                                  * Guest OS가 직접 서비스에 접근할 수 있는 반 가상화 인터페이스
                                                                  * 애플리케이션에서 수행하는 Supervisor call과 비슷
                                                                  * Xen Project Architecture
  
                                                                     * Bare-metal hypervisor이다. (Type-1)
                                                                     * 다만 설계가 일반적인 Bare-metal과 다름
                                                                     * Hypervisor가 Native driver를 가지지 않음.
                                                                     * 얇은 layer
                                                                     * I/O function 관련 기능이 없음
                                                                     * Networking, storage, ...
                                                                     * CPU, Memory, Interrupts 관리만
                                                                     * 이거 없으면 Xen은 쓸모가 없음
                                                                     * VM0 (Domain 0) [Control Domain]
                                                                     * Xen을 위한 특별한 Virtual Machine
                                                                     * 가장 먼저 실행됨
                                                                     * Native driver는 여기 설치됨
                                                                     * 모든 I/O function들을 수행
                                                                     * System Service들도 여기서 구동
                                                                     * VMn (Domain Un)
                                                                     * Guest Virtual Machine
                                                                     * I/O 요청이 있으면 control domain을 통해서 수행
                                                                     * unprivileged
                                                                     * Paravirtualized guest들은 PV-enabled된 OS를 필요로 함.
                                                                     * Linux는 3.0부터 기본적으로 지원하고 있다. (Xen Project-enabled)
                                                                     * 또한 hypervisor관련 tool들을 package로 보유함
                                                                     * Guest의 PV I/O 작동 예
  
  

  

가상화와 성능의 문제
                                                                        * Native > 반가상화 > 전가상화 > 에뮬레이션
                                                                        * 성능 연구
                                                                        * NIC: SR-IOV
                                                                        * GPU: Nvidia vGPU (GRID K Series, ...)
                                                                        * NUMA effect를 고려한 Multi-core CPU


가상머신의 Isolation(독립성)
  

                                                                        * 가상의 자원을 할당받는다는 것은 하드웨어의 특정 영역에 접근 권한을 받는다는 뜻.
                                                                        * 가상머신은 동일 하드웨어에서 구동되더라도 VM 하나가 맛이 가도 다른 VM들에게 영향을 주지 않는다.
                                                                        * 가상머신은 작동 중 할당된 가상자원을 변경할 수 없음
                                                                        * 반면 container는 할당자원을 runtime에 변경이 가능함
Container-based Virtualization
  

                                                                        * 모듈화 되고 격리된 컴퓨팅 공간
                                                                        * 경량 컨테이너 엔진
                                                                        * 프로세스를 격리하고 모듈화 된 프로그램 패키지로서 수행
                                                                        * 기존 가상머신에 비해 가볍고 빠르다


Basic Concepts of Container
                                                                        * LXC (LinuX Container)
                                                                        * OS레벨의 가상화 기법
                                                                        * IBM Namespace + Google cgroup = LXC
                                                                        * namespace
                                                                        * process 사이에 벽을 만듦
                                                                        * cgroup
                                                                        * cpu, memory 등의 자원을 관리하여 특정 application이 과도하게 자원을 점유하는 것을 방지
                                                                        * LXC는 GNU(LGPLv2.1+) 오픈소스
                                                                        * 경량화로 인한 속도와 이식성
                                                                        * 운영체제를 제외한 application 실행에 필요한 모든 파일을 패키징
                                                                        * OS-level virtualization
                                                                        * 유연한 자원 배분 기능
                                                                        * 실행 중 자원할당 조정 가능
                                                                        * 더 많은 응용프로그램을 하나의 물리적 서버에서 구동 가능
  
                                                                           * Vertical Elasticity
                                                                           * scale up, down은 용이
                                                                           * CPU, Memory 추가 제거
                                                                           * scale out과는 다른 개념
                                                                           * 인스턴스 증가 감소
                                                                           * 기존의 Hypervisor에선 하기 어렵다
                                                                           * 가상머신보다 시스템 요구사항이 적다
                                                                           * Image 크기가 작음
                                                                           * 배포 용이
                                                                           * 운영체제 부팅이 필요 없음
                                                                           * 서비스 시작 시간이 짧다
                                                                           * 시스템의 성능부하가 적음
                                                                           * Container는 application 하나 실행하는 수준의 자원만 필요
Docker and Cloud computing
                                                                           * Open source 기반 Container 관리 platform
                                                                           * Based on LXC
                                                                           * 이식성 향상, 데이터와 코드의 분산된 관리, 프로그램 스택의 간결&명료함
                                                                           * CPU 자원이나 Memory 자원을 동적으로 조절 가능함.
                                                                           * 단, port forwarding이나 container간 link는 처음 설정해야 함.
(중간에 변경 불가)
                                                                              * History
                                                                              * FreeBSD Jails
                                                                              * Linux VServer
                                                                              * Solaris Zones
                                                                              * Google cgroup
                                                                              * redhat Namespace
                                                                              * IBM LXC
                                                                              * Docker
                                                                              * Docker는 Linux 위에서만 동작
  
                                                                                 * 만약 Non-Linux에서 Docker를 굴리려면 Hypervisor 위에 Linux를 올리고 그 위에 Docker engine을 실행
                                                                                 * Container Image (Dockerfile)
                                                                                 * Not container
                                                                                 * Container로 실행할 대상
                                                                                 * Software
                                                                                 * Runtime Environment
                                                                                 * Docker Image는 수정이 불가능 하다
                                                                                 * 실행 중 추가되거나 변경된 값은 현재 container의 R/W Layer에 저장
                                                                                 * Union File System (images are comprised of multiple layer)
                                                                                 * 수정된 사항을 적용하려면 다시 image로 패키징
                                                                                 * Original image layer는 변형이 안 됨
                                                                                 * 웬만해선 실행중인 상태로 이미지화 하지는 말자
  



  

                                                                                 * Client, Docker_Host: Local Machine
                                                                                 * Registry: Docker Hub


Docker Hub
                                                                                 * https://hub.docker.com


                                                                                 * Container as a Service (CaaS)
  

                                                                                 * 경량배포가 가능하다는 점이 이런 서비스(CaaS)도 가능하게 함.
________________
                                                                                    * Container-based Cloud operating system
                                                                                    * 다수의 Container(service)의 실행 관리 및 조율(Orchestration)
기능
	내용
	서비스 디스커버리
(Service Discovery)
	서비스 탐색 기능으로 기본적으로는 클라우드 환경에서 컨테이너의 생성과 배치 이동여부를 알 수 없기에 IP, Port 정보 업데이트 및 관리를 통해 서비스를 지원함
	스케일링
(Scaling)
	로드밸런싱
(Load Balancing)
	생성된 컨테이너의 컴퓨팅자원 사용량의 설정 및 자동배분
	스케줄링
(Scheduling)
	늘어난 컨테이너를 적합한 서버에 나누어 배포하고, 서버가 다운될 경우 실행 중이던 컨테이너를 다른 서버에서 구동시킴
	클러스터링
(Clustering)
	여러 개의 서버를 묶어 하나의 서버처럼 사용할 수 있도록 지원하거나, 가상네트워크를 이용하여 산재된 서버를 연결시켜줌
	로깅/모니터링
(Logging/Monitoring)
	여러 개의 서버를 동시에 관리할 경우 한 곳에서 서버 상태를 모니터링 하고 로그 관리를 할 수 있도록 함
	

                                                                                    * 주요 Orchestration platform
구분
	구글 Kubernetes
	도커 Swarm
	아파치 Mesos
	특징
요약
	다양한 테스트를 만족하는 안정적인 솔루션
	사용이 용이한 솔루션
	UI 수준이 높고 기능이 풍부하나 설치 및 관리가 어려운 솔루션
	운영가능
host 머신
	1,000 nodes
	1,000 nodes
	10,000 nodes
	관리
서비스
	Google Container Engine
	Docker Cloud, SDN
	Azure Container Service
(MS)
	기술자료
	기술자료가 매우 풍보하고 CNCF와 협력이 많아 클라우드 친화적임
	기술 자료가 풍부하고 개념과 기능이 간결한편
	MS와 Mesosphere가 적극적으로 지원하나 기술 자료가 부족한편
	라이센스
모델
	아파치
	아파치
	아파치
	

                                                                                    * 이 외에도yarn이라는 orchestration platform이 존재한다.
                                                                                    * DevOps: SW 개발자와 운영자 간의 소통과 협업을 강조하는 개발 환경
                                                                                    * Container 기반 클라우드의 초석
                                                                                    * Container 기술은 클라우드 컴퓨팅과 동반 성장
                                                                                    * 한계점도 분명함
                                                                                    * 고 수준의 isolation이 안 됨
                                                                                    * OS환경이 Host OS에 종속된다
                                                                                    * Kernel 공유로 보안성, 안정성 이슈가 있음
                                                                                    * 서버 가상화 기술과 상호 보완하면서 공존할 것으로 보임
Cloud Programming Model: MapReduction
                                                                                    * 컴퓨팅 환경이 변하고 있다.
                                                                                    * from
                                                                                    * non-centralized distributed system architecture
                                                                                    * 지리적으로 분산된 환경 (grid computing)
                                                                                    * to
                                                                                    * centralized cloud computing architecture
                                                                                    * 어딘가에 있는 중앙집중형 시스템(cloud)
                                                                                    * data centers are owned and maintained by third party
                                                                                    * Motivation
                                                                                    * low cost of system hardware
                                                                                    * increase in computing power and storage capacity
                                                                                    * massive growth in data size generated by digital media, web authoring, scientific instruments, physical simulations, etc…
                                                                                    * > main challenge in the cloud is how to effectively
                                                                                    * store, query, analyze, utilize(활용)
                                                                                    * Traditional data-intensive system은 cloud computing에 효과적이지 못함
                                                                                    * traditional: super computer 같은 것들을 사용했었음
                                                                                    * cluster, grid computing
                                                                                    * data to computing paradigm
                                                                                    * Job: 여러개의 task묶음
                                                                                    * 기존 것은 computing node와 storage가 분리되어 있었음
                                                                                    * internet, intranet의 bottleneck이 발생
                                                                                    * New paradigms should be adopted!
                                                                                    * computing & data resource가 같이있어야(co-located) 한다.
                                                                                    * minimizing the communication cost
                                                                                    * benefiting from the large improvements in IO speeds using local disk
                                                                                    * 데이터가 있는 쪽에 computation을 보내는 것이 패러다임이 됨
  

                                                                                    * Computing To Data는 장벽이 올라감
                                                                                    * 추상화가 더 잘 되어 있음
                                                                                    * traditional에선 Application이 하드웨어를 직접 제어하여야 했음.
Cloud Computing Program
                                                                                    * Google MapReduce
                                                                                    * Google File System의 상위 단계에서 돌아가는 시스템
                                                                                    * runtime역할을 한다
                                                                                    * data는 chunk 단위로 partitioned.
                                                                                    * chunk는 복제(replicated)된다.
                                                                                    * data processing이 data storage와 co-located 됨
                                                                                    * data locality를 효율적으로 활용
                                                                                    * 데이터 집약형 클라우드 컴퓨팅 프로그래밍(Data-intensive cloud computing programming)의 가장 강력한 구현 결과물
                                                                                    * Hadoop
                                                                                    * 구글이 내부적으로 사용하고 논문 낸 것을 Yahoo가 Open source로 개발함
MapReduce Programming Model
                                                                                    * Software framework
                                                                                    * large-scale computing problem을 해결하기 위해 나옴
                                                                                    * Map과 Reduce로 표현됨 (함수형 언어 Lisp의 가장 많이 쓰는 함수)
                                                                                    * map (key1, value1) -> list (key2, value2)
                                                                                    * reduce(key2, list(value2)) -> list (value2)
                                                                                    * 데이터 입력의 단위는 chunk


MapReduce programming의 예
  

                                                                                    * Splitting, Shuffling은 알아서 해줌
                                                                                    * key는 chunk에서 시작위치
                                                                                    * 보통은 쓸모 없음
                                                                                    * Mapping은 independence task이다
                                                                                    * 사용자가 프로그래밍
                                                                                    * key-value로 매핑
                                                                                    * Splitting과 Mapping은 최대한 가깝게(Co-located)
                                                                                    * 이 작업은 MapReduce가 알아서 해줌
                                                                                    * Shuffling
                                                                                    * 같은 키를 공유하는 것 끼리 모아줌
                                                                                    * Reducing (Aggregation)
                                                                                    * 사용자가 프로그래밍
                                                                                    * 전 단계에서 모아준 { key, [value] }의 value들을 처리
                                                                                    * 여기선 더하기
Main Feature
                                                                                    * Data-Aware
                                                                                    * 데이터의 위치정보를 고려한다(takes in consideration the data location information)
                                                                                    * co-locality 실현을 위함
                                                                                    * Simplicity
                                                                                    * MapReduce runtime은 개발자 로직만 집어넣어주면 co-locality를 고려한 computing node 할당이나, 병렬처리이든 다 알아서 잘 해줌
                                                                                    * Manageability
                                                                                    * input이든 output이든 GFS에 있음
                                                                                    * 관리가 쉽다.


  



                                                                                    1. Data Local: Data Local이 불가능하면 Rack Local을 시도
                                                                                    2. Rack Local: Rack Local이 불가능 하면 Different Rack으로 시도
                                                                                    3. 요점은 Map task와 Data block을 최대한 가깝게 유지하는 것


                                                                                    * Scalability (Scale-out)
                                                                                    * MapReduce는 분산 병렬 처리
                                                                                    * 시스템에 Node를 추가하면 알아서 효과적으로 performance가 증가함
                                                                                    * potentially only minor losses
                                                                                    * 성능 손해가 적은 편
                                                                                    * Fault Tolerance and Reliability
                                                                                    * taking advantage of the replication in GFS.
                                                                                    * GFS는 chunk단위로 분산저장만 할 뿐 아니라 복제저장도 한다.
                                                                                    * re-running all the tasks (completed or in progress) when a host node is going off-line
                                                                                    * 다운 된 node의 task들은 다른 node에서 모두 재실행
                                                                                    * re-running failed tasks on another node
                                                                                    * 실패한 task는 다른 노드에서 재실행
                                                                                    * launching backup tasks when these tasks are slowing down(stragglers) and causing a bottleneck to the entire job
                                                                                    * straggler: 지연되는 작업
                                                                                    * 지연되는 작업은 다른 node에서 백업실행
                                                                                    * 이 모든것이 알아서 이루어진다.
Components of Hadoop(Modules)
                                                                                    * Hadoop Common
                                                                                    * common utilities
                                                                                    * Hadoop Distributed File System(HDFS)
                                                                                    * Hadoop YARN
                                                                                    * job scheduling & cluster resource management를 위한 framework
                                                                                    * Hadoop MapReduce
                                                                                    * YARN-based system for parallel processing of large data sets




Virtual Machine + Docker 실습
                                                                                    * Docker는  Linux 기반
                                                                                    * Windows / Mac OS에 설치할 경우
                                                                                    * Docker for Windows
                                                                                    * Hyper-V를 이용한 Docker
                                                                                    * Docker for Mac
                                                                                    * Mac OS >= 10.13
                                                                                    * Mac Hardware >= 2010
                                                                                    * https://hub.docker.com
                                                                                    * Docker Toolbox
                                                                                    * 옛 버전의 OS에 설치할 때 사용하는 툴
                                                                                    * 가상머신 + Docker (private cloud 환경 구성)
                                                                                    * 리눅스 외에 Docker를 구성하는 방법
                                                                                    * Hypervisor 위에 Linux 올리기
                                                                                    * 그 위에 Docker 설치
                                                                                    * 별도의 Linux 서버가 필요하지 않다.
                                                                                    * Container Application 개발용도로 적합하다.
                                                                                    * Docker와 가장 잘 호환되며 관련자료가 많은 OS는 Ubuntu
                                                                                    * VMWare + Ubuntu 18.04 LTS




Ubuntu에 Docker 설치하기
https://docs.docker.com/engine/install/ubuntu/
                                                                                    1. 만약에 기존 Docker를 지울거면
$ sudo apt-get remove docker docker-engine docker.io containerd runc
Set up the repository
                                                                                       2. Update the apt package index and install packages to allow apt to use a repository over HTTPS:
$ sudo apt-get update
$ sudo apt-get install \
   apt-transport-https \
   ca-certificates \
   curl \
   gnupg \
   lsb-release
                                                                                       3. Add Docker’s official GPG key:
$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
                                                                                       4. Set up the stable repository.
$ echo \
 "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg]
https://download.docker.com/linux/ubuntu \
 $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
Install Docker Engine
                                                                                          5. Update the apt package index, and install the latest version of Docker Engine and containerd, or go to the next step to install a specific version:
$ sudo apt-get update
$ sudo apt-get install docker-ce docker-ce-cli containerd.io
Check Installation
                                                                                             6. Check Docker Version
$ sudo docker version
                                                                                             7. Try run “hello-world” image
$ sudo docker run hello-world
// 만약 이미지가 없으면 docker hub에서 image를 pulling 해서 실행함.
                                                                                             8. Ubuntu Docker image 실행해보기
$ sudo docker run -it ubuntu bash
                                                                                             9. Docker 상태 확인하기(container list view)
$ sudo docker ps
                                                                                             10. 이미지 확인하기
$sudo docker images
Docker Image와 Container
Docker Architecture Diagram
  

Docker Image
                                                                                                * Container를 생성할 때 필요한 요소, .ISO와 같은 개념
                                                                                                * 설치파일?
                                                                                                * 여러개의 계층으로 된 binary file, container 생성, 실행 시 읽기 전용
                                                                                                * Image Name:
                                                                                                * [repository_name]/[image_name]:tag
                                                                                                * 저장소 이름이 명시되지 않으면 docker hub의 공식 이미지
Docker Container
                                                                                                * Docker image를 활용해서 생성한 instance
                                                                                                * Filesystem,
                                                                                                * Isolated system resource and network를 사용할 수 있는
독립된 공간이 생성됨
                                                                                                * Docker Image와 Container는 1:N 관계
  
                                                                                                * Container는 Image를 읽기 전용으로 사용
                                                                                                * 변경된 사항은 Container 계층에 저장
                                                                                                   * Container에서 뭔 짓을 해도 Image에는 영향을 주지 않는다.
                                                                                                   * 각 Container는 독립된 파일시스템을 제공받으며 호스트와 분리되어 있다.
                                                                                                   * 특정 Container에 어떤 Application을 설치하거나 삭제해도 다른 Container나 Host에는 변화가 없다.
  

                                                                                                   * Docker는 Hypervisor Virtualization에 비해 낮은 수준의 분리를 제공한다.
Docker Container 실습
  

                                                                                                   * Container 생성
                                                                                                   * -i -t 옵션은 Container와 상호 입출력을 가능하게 함
                                                                                                   * ubuntu:14.04 이미지가 로컬에 존재하지 않으면 자동으로 Docker hub에서 다운로드(pull)
                                                                                                   * Container의 기본 사용자는 root, 호스트 이름은 무작위 16진수 해시값
                                                                                                   * exit는 컨테이너에서 빠져나오면서 동시에 컨테이너를 정지
  

                                                                                                   * docker pull 명령어를 이용해서 이미지를 미리 다운로드 할 수 있음.
                                                                                                   * docker images 명령어로 현재 local에 저장된 image들을 볼 수 있음.
  

                                                                                                   * docker create
                                                                                                   * container 생성 , 실행은 하지 않음
                                                                                                   * docker start
                                                                                                   * 생성된 container를 실행
                                                                                                   * docker attach
                                                                                                   * container 내부로 들어감
                                                                                                   * IO 출력을 현재 console에 연결한다.
                                                                                                   * Ctrl + P, Q 를 입력하면 container 정지 없이 빠져나올 수 있음
                                                                                                   * docker ps
                                                                                                   * 현재 실행중인 container 목록 확인
                                                                                                   * docker run
                                                                                                   * container를 생성하고 실행한다
                                                                                                   * image layer위에 writeable container layer가 생성됨
                                                                                                   * docker ps -a
                                                                                                   * 정지된 container를 포함한 모든 container를 출력한다.
                                                                                                   * docker rm
                                                                                                   * 해당하는 container를 삭제
                                                                                                   * 실행중인 container는 삭제 불가
                                                                                                   * docker rm -f : 로 강제 삭제 가능
                                                                                                   * docker stop
                                                                                                   * container를 중지시킴
                                                                                                   * docker container prune
                                                                                                   * 모든 container를 삭제
                                                                                                   * container를 외부에 노출시키기
  
                                                                                                      * -p 옵션으로 container와 host의 port를 binding 할 수 있음
                                                                                                      * sudo docker run -it —name container_name -p host_port:container_port image
                                                                                                      * container를 외부에 노출시키고 apache서버를 설치한 모습
  
                                                                                                      * host에서 ifconfig로 host 아이피 확인 가능
                                                                                                         * Container Application 구축하기
Composed Docker Applications in a Cluster
  
                                                                                                            * 서비스 단위로 재활용 가능한 모듈처럼 사용 가능함
                                                                                                            * Wordpress Blog 서비스 만들어보기
  
                                                                                                               * Database Container
                                                                                                               * sudo docker run -d —name wordpressdb \
-e MYSQL_ROOT_PASSWORD=password \
-e MYSQL_DATABASE=wordpress mysql:5.7
                                                                                                                  * -e는 환경변수 설정
                                                                                                                  * docker image는 mysql:5.7
                                                                                                                  *   
Wordpress Web Server Container
                                                                                                                  * --link 두 container를 연결한다.
                                                                                                                     * wordpressdb:mysql
                                                                                                                     * container의 의존성도 정의된다.
                                                                                                                     * -p 80
                                                                                                                     * host의 임의의 port를 “wordpress” container의 80 port에 연결한다.
                                                                                                                     * 이 경우 host의 port를 명시하지 않았기 때문에 임의의 port가 할당된다.
                                                                                                                     * 할당 된 포트를 알아보려면
                                                                                                                     * sudo docker port wordpress
                                                                                                                     * -d 
                                                                                                                     * detached모드
                                                                                                                     * background로 실행, 사용자의 입력을 받지 않음
                                                                                                                     * 만약 실행되는 application이 없으면 자동 종료됨
                                                                                                                     * sudo docker exec
                                                                                                                     * 컨테이너 내부에서 실행한 결과를 return
                                                                                                                     * 별도의 console을 제공
                                                                                                                     * exit를 사용해서 나가더라도 컨테이너가 종료되지는 않는다.


Docker Volume
                                                                                                                     * https://docs.docker.com/storage/volumes/
                                                                                                                     * Container의 데이터를 영속적으로 보존
Container Resource Allocation
                                                                                                                     * https://docs.docker.com/config/containers/resource_constraints/
Dockerfile
                                                                                                                     * https://docs.docker.com/engine/reference/builder/
                                                                                                                     * commit & push
                                                                                                                     * https://eungbean.github.io/2018/12/03/til-docker-commit/






Hadoop Distributed File System (HDFS)


Design Principles
Basic Concepts of HDFS
De facto standard for Big data store and processing platform
(사실상 표준)


Roots of Hadoop
MapReduce와 GFS 논문에서 시작
HDFS Paper
                                                                                                                     * store very large data set reliably
                                                                                                                     * to stream those dataset at high bandwidth to user application
                                                                                                                     * distributing storage
                                                                                                                     * computation across many servers
Yahoo can managed 25 petabytes by HDFS
Hadoop Project
                                                                                                                     * Provides
                                                                                                                     * Distributed file system (분산파일시스템)
                                                                                                                     * MapReduce
                                                                                                                     * Analysis
                                                                                                                     * transformation
                                                                                                                     * Partitioning of data, computation across many host
                                                                                                                     * 양이 너무 많아 저장도 분산, 처리도 분산해야 함
                                                                                                                     * computation을 data에 근접시켜서 병렬(parallel close) 처리
                                                                                                                     * 기존의 Commodity server를 추가하는 것으로 쉽게 Scalable하다.
                                                                                                                     * computation capacity
                                                                                                                     * storage capacity
                                                                                                                     * IO bandwidth
                                                                                                                     * An Apache Open Source Project
                                                                                                                     * Yahoo가 80% 만듦
  

Hadoop Ecosystem
  

Why Distributed File Systems
                                                                                                                     * Single physical machine에 넣기에 너무 많다.
                                                                                                                     * partition: 여러 기계에 분산해서 저장하고 처리할 필요성이 있다.
                                                                                                                     * Distributed file system: 분산된 파일을 관리할 수 있는 시스템
                                                                                                                     * network로 연결되어있는 여러 storage를 하나로 관리할 수 있다.
                                                                                                                     * Challenge
                                                                                                                     * Node failure: node가 언제든지 죽을 수 있다
                                                                                                                     * tolerate node failure without suffering data loss
                                                                                                                     * HDFS: Hadoop flag file system
                                                                                                                     * Hadoop은 File System Abstraction (추상화 수준이 높다)
                                                                                                                     * HDFS뿐 아니라, 여러 타입의 storage를 붙일 수 있음
                                                                                                                     * 로컬 머신 뿐 아니라 Amazon S3 같은 가상 스토라지도 붙일 수 있다.
The Design of HDFS
                                                                                                                     * Very large file
                                                                                                                     * Streaming data access
                                                                                                                     * write-once, read-many-times pattern
                                                                                                                     * 전체 데이터를 읽는 시간이 첫 번째 데이터를 읽는 시간 보다 중요하다
                                                                                                                     * sequential access에 동작이 맞추어져 있음
                                                                                                                     * random access는 안 맞음
                                                                                                                     * Commodity hardware
                                                                                                                     * 전용 하드웨어를 필요로 하지 않다.
                                                                                                                     * 여러 제조사 물건들을 붙일 수 있다.
                                                                                                                     * Pros.: 구축 비용, scaling 비용이 저렴하다.
                                                                                                                     * Cons.: Node failure확률이 높아진다
                                                                                                                     * HDFS는 node failure를 염두해두고 설계되어있다.
                                                                                                                     * HDFS의 약점
                                                                                                                     * Low-latency data access
                                                                                                                     * access레이턴시는 낮지만, transfer throughput은 매우 높다.
                                                                                                                     * random access에 매우 약함
                                                                                                                     * Lots of small files
                                                                                                                     * namenode > memory에 상주
                                                                                                                     * namenode의 메모리에 의해 전체 파일 개수가 결정된다.
                                                                                                                     * 때문에 작은 파일을 대량으로 다루는 것에 매우 약하다.
                                                                                                                     * Yahoo는 3500개의 file node밖에 관리 못 했음
                                                                                                                     * Master node는 빵빵할 필요가 있음
                                                                                                                     * Multiple writers, arbitrary file modifications
                                                                                                                     * HDFS는 Single writer만 가능
                                                                                                                     * 한 번 쓴 파일은 수정 못함
Architecture
HDFS Architecture
  
                                                                                                                     * Metadata와 Application data를 분리(separately)해서 저장
                                                                                                                     * Metadata - namenode
                                                                                                                     * 각 block의 위치정보
                                                                                                                     * filepath
                                                                                                                     * replicas 관리
                                                                                                                     * Application data - datanode
                                                                                                                     * 각 node들은 TCP based protocol로 묶여있음
HDFS Block
                                                                                                                     * a unit of read or write
                                                                                                                     * 64MB
                                                                                                                     * 큰 파일은 block단위로 나눔
                                                                                                                     * a large block to minimize the cost of seeks
                                                                                                                     * 큰 block size는 transfer time을 seek time보다 줄일 수 있다.
                                                                                                                     * each block of file is independently replicated at multiple datanodes
                                                                                                                     * 보통 3개의 노드에 복제되어 분산저장된다.
                                                                                                                     * failure recovery
                                                                                                                     * better performance
                                                                                                                     * cons.
                                                                                                                     * storage utilization에 안 좋음(공간낭비)
NameNode
                                                                                                                     * Metadata
                                                                                                                     * Namespace tree(filepath)
                                                                                                                     * includes ownership, permission, quotas, replication factor
                                                                                                                     * Block의 physical location
                                                                                                                     * NameNode는 block location을 persistently하게 저장하지 않는다 (metadata는 보존)
                                                                                                                     * 시스템 시작 때 local data와 data node들로부터 받은 정보로 reconstructed함.
                                                                                                                     * block location정보는 부팅 때 datanode가 보고함.
                                                                                                                     * 모든 데이터는 memory에서만 관리
                                                                                                                     * 다만 재시작을 대비해 Local storage에 저장
                                                                                                                     * Secondary NameNode
                                                                                                                     * Main NameNode로부터 모든 정보를 백업받는다.
                                                                                                                     * Main NameNode가 복구 불가능한 수준으로 파괴되면 Admin에 의해 대체할 수 있음
DataNodes
                                                                                                                     * Block과 metadata를 같이 저장
                                                                                                                     * checksums
                                                                                                                     * generation stamp
                                                                                                                     * Starting up process
                                                                                                                     * handshaking to verify the namespace ID, software version of DataNode
                                                                                                                     * registers with NameNode and persistently store the unique storage ID
                                                                                                                     * Block report
                                                                                                                     * 주기적으로 수행
                                                                                                                     * block id
                                                                                                                     * generation stamp
                                                                                                                     * length for each block replica the server hosts
                                                                                                                     * 첫 수행은 registration때 즉각 발생
                                                                                                                     * 그 이후로도 매 시간마다 수행
                                                                                                                     * Maintaining the overall system integrity
                                                                                                                     * Heartbeats
                                                                                                                     * 3초마다
                                                                                                                     * 10분 정도 지났는데도 안 오면 namenode는 이 node를 죽은것으로 판단함
                                                                                                                     * Heartbeat information
                                                                                                                     * total storage capacity
                                                                                                                     * faction of storage in use
                                                                                                                     * number of transfers currently in progress
                                                                                                                     * 위의 정보들을 토대로 namenode는 load balancing, space allocation을 결정한다.
                                                                                                                     * Piggybacking (namenode의 응답)
                                                                                                                     * replicate blocks to other nodes
                                                                                                                     * remove local block replicas
                                                                                                                     * re-register or shut down the node
                                                                                                                     * send an immediate block report
HDFS Client
                                                                                                                     * Access the file system on behalf of the user by communicating with the NameNode and DataNode
                                                                                                                     * Reading a file
  
                                                                                                                        1. NameNode에서 원하는 Data Block이 저장된 DataNode의 list를 받는다.
                                                                                                                        1. 접근하기 가장 가까운 곳 부터 ordering되어 전달됨
                                                                                                                        2. DataNode에 직접 접근해서 Block을 요청한다.
                                                                                                                        1. 요청이 datanode들에 분산되기 때문에 동시다발적인 요청에 강하다.
                                                                                                                        * Writing a file
  
                                                                                                                           1. NameNode에게 현재 Block의 데이터가 저장될 DataNode의 list를 받는다.
                                                                                                                           2. node-to-node를 위한 pipeline 생성
                                                                                                                           3. 현재 쓰고 있는 Block이 다 차면 모든 데이터가 쓰여질때까지 1)로 되돌아간다
Basic Functionality
File I/O and Replica Management
                                                                                                                           * 기본적으로 이미 작성된 데이터에 대해선 Readonly임
                                                                                                                           * Dealing with the integrity of the data
                                                                                                                           * Checksums verification
                                                                                                                           * 문제가 있으면 namenode에 보고
                                                                                                                           * Namenode는 오염된 데이터를 지우고 복제본으로 복구를 할 것
                                                                                                                           * Reading a file based on the proximity
                                                                                                                           * Namenode는 block 위치 요청에 대해 Client로부터 distance순으로 ordered해서 list를 전달
                                                                                                                           * closest replica first
                                                                                                                           * Network Topology and Hadoop
  
                                                                                                                              * 대역폭이 가장 정확하지만 일정하지가 않음
                                                                                                                              * 때문에 Node상의 물리적 거리를 가지고 사용한다.
                                                                                                                              * 이 거리가 Hop
                                                                                                                              * Hop은 Network tree에서 특정 Node들끼리 통신하는데 걸리는 node들의 수
                                                                                                                              * 예를 들어 Node 1.1 > Node 1.2
                                                                                                                              * Node1.1 >  Rack1 > Node1.2 = 2 hops
                                                                                                                              * Node 1.1 > Node 3.1
                                                                                                                              * Node 1.1 > Rack1 > Data center > Rack3 > Node 3.1 = 4 hops
                                                                                                                              * 거리와 속도
  
                                                                                                                                 * Block Placement
  
                                                                                                                                    * Node는 여러개의 rack에 걸쳐 있을 것이라 가정
  
                                                                                                                                    * 어느 Datanode라도 동일한 복제 block을 보유하지 않는다.
                                                                                                                                       * replica의 의미가 없어짐
                                                                                                                                       * 하나의 Rack에는 2개 이상의 복제 block을 보유하지 않는다.
                                                                                                                                       * 특정 Rack이 나가더라도 그 Rack이 보관중이던 모든 데이터들에 대해 적어도 하나 이상의 replica block이 다른 Rack에 존재할 것이다.
                                                                                                                                       * 하나의 Rack에 2개의 replica가 있는 이유는 process가 해당 Node에서 이루어지지 않더라도 해당 Rack에서는 가능하게끔 하여 성능 향상을 노린 것이다.
                                                                                                                                       * Replication management
                                                                                                                                       * 적어도 3개 복제
                                                                                                                                       * under replicate
                                                                                                                                       * 늘린다
                                                                                                                                       * over replicate
                                                                                                                                       * 줄인다
                                                                                                                                       * Balancer
                                                                                                                                       * DataNode들의 Disk usage가 고르게 분포되도록 데이터가 최대한 분산되어 저장될 수 있게끔 정리해주는 tool
                                                                                                                                       * 보통 administrator가 수동으로 돌린다
                                                                                                                                       * Block scanner
                                                                                                                                       * Datanode들이 주기적으로 실행
                                                                                                                                       * 데이터 상태 등을 점검 (checksum 등)
                                                                                                                                       * Graceful leaving of a DataNode
                                                                                                                                       * DataNode를 폐기하기 전 decommissioning marking을 하면
                                                                                                                                       * decommissioning하는 동안 read request는 계속 제공함
                                                                                                                                       * Decommissioning process
                                                                                                                                       1. NameNode는 replication block들을 다른 DataNode로 옮기게끔 schedule한다
                                                                                                                                       2. 모든 block들이 옮겨지면 해당 DataNode는 decommissioned state로 전환
                                                                                                                                       3. 이제 안전하게 DataNode를 제거할 수 있다
________________


Utilizing HDFS
Command-Line Interface
                                                                                                                                       * Basic Filesystem Operation
                                                                                                                                       * reading file, creating directories, moving files, deleting data, listing directories, ..
                                                                                                                                       * hadoop fs- help
  

                                                                                                                                       * 기본적으로 HDFS는 POSIX-compliant하지 않다
  



Hadoop Filesystems
                                                                                                                                       * Hadoop은 abstract한 filesystem을 가지고 있다.
org.apache.hadoop.fs.FileSystem
HDFS는 해당 abstract class를 구현한 것 중 하나
  
                                                                                                                                          * 따라서 해당 abstract를 제공할 수 있다면 HDFS대신 다른 어떤 storage도 붙일 수 있다.
                                                                                                                                          * Hadoop function들이 서로 다른 환경에서도 코드 변경 없이 작동할 수 있다
                                                                                                                                          * Lustre
                                                                                                                                          * Interfaces
                                                                                                                                          * Java API
                                                                                                                                          * FileSystem also interface
                                                                                                                                          * HTTP
                                                                                                                                          * HTTP REST API (WebHDFS)
                                                                                                                                          * 다소 느리다
                                                                                                                                          * C
                                                                                                                                          * C library (libhdfs)
                                                                                                                                          * WebHDFS (libwebhdfs)
                                                                                                                                          * FUSE
                                                                                                                                          * Filesystem in Userspace (FUSE)
                                                                                                                                          * local system에 mount해서 사용 가능
                                                                                                                                          * ndrive같은 utility drive처럼 동작한다
                                                                                                                                          * Unix filesystems에 integrated되어 돌아간다
                                                                                                                                          * 범용성이 좋음
                                                                                                                                          * 수정이 안 된다.
                                                                                                                                          * NFS
                                                                                                                                          * mount HDFS (NFSv3) kernel 레벨에서 마운트
                                                                                                                                          * POSIX library 사용 가능하다
                                                                                                                                          * application 레벨에서 동작 가능
                                                                                                                                          * 수정이 안 된다.
                                                                                                                                          * POSIX인터페이스를 제공한다고 HDFS의 단점을 극복할 수 있는 건 아님
                                                                                                                                          * 성능이 좋음


Advanced Features of HDFS
HDFS Federation
                                                                                                                                          * Namenode들을 두 개 이상 묶어서 사용 가능
                                                                                                                                          * 더 많은 파일들을 저장 가능해짐
                                                                                                                                          * namespace들을 분할해서 관리
                                                                                                                                          * 각 namenode들끼리는 통신할 필요가 없음
                                                                                                                                          * datanodes register with each namenode in the cluster and store blocks from multiple block pools
HDFS High Availability
                                                                                                                                          * 아직 무리이다
                                                                                                                                          * namenode가 죽으면 끝
                                                                                                                                          * Namenode is SPOF = Single point of failure
                                                                                                                                          * 모든 작업에 namenode가 관련됨
                                                                                                                                          * To recover from a failed namenode…
                                                                                                                                          * 새 namenode를 달아서 부팅
                                                                                                                                          * 큰 규모의 cluster에서는 복구에 30분이 걸리기도 함.


  

                                                                                                                                          * active-standby
                                                                                                                                          * 하나는 작동
                                                                                                                                          * 하나는 대기 (상태를 계속 전달받아서 active state와 일치시킴)
                                                                                                                                          * Datablock들은 active, standby node 양 측에 전부 상태를 보고
                                                                                                                                          * active, standby는 storage를 공유(journal node)
                                                                                                                                          * architecture 변형
                                                                                                                                          * client는 namenode들에 대해 알고 있음 (active, standby)
                                                                                                                                          * 문제가 생기면 수십초 만에 다시 복구
                                                                                                                                          * Journal Node
                                                                                                                                          * Highly available shared storage
                                                                                                                                          * HDFS에서 제공하는 스토라지는 아님
                                                                                                                                          * 별도의 고가용성 스토라지를 붙여서 구현
                                                                                                                                          * NAS등 무엇이든 가능


Hadoop 3.0 Major Features
                                                                                                                                          * Java 8  (old is 7)
                                                                                                                                          * Erasure Encoding (option)
  

                                                                                                                                          * Storage space reduce (50%)
                                                                                                                                          * 성능상으로는 안 좋아짐(?)
                                                                                                                                          * 각 노드들이 RAID5 DISK인것처럼 동작
                                                                                                                                          * Multiple standby namenode (option)
  
________________


Apache Hadoop 설치하기
                                                                                                                                             * Standalone mode
                                                                                                                                             * One local device
                                                                                                                                             * distribute environment test 불가능
                                                                                                                                             * Pseudo-distributed mode
                                                                                                                                             * One local device
                                                                                                                                             * HDFS, MapReduce와 관련된 데몬들을 하나의 장비에서 실행
                                                                                                                                             * 가상화 머신을 여러개 갖추어 마치 분산되어 동작하는 것 처럼 보이게 할 수 있다.
                                                                                                                                             * Fully distributed mode
                                                                                                                                             * Multiple device
                                                                                                                                             * Serve live service with Hadoop


하둡 설치 방식
  

가상 분산 모드 + 컨테이너




Docker 이미지로 설치하기
$ sudo docker pull jiksoo75/hadoop1-mju:latest
$ sudo docker images
                                                                                                                                             * jiksoo75/hadoop1-mju가 있으면 다운로드 완료


Interactive Mode로 실행하기
$ sudo docker run -i -t --name hadoop-practice jiksoo75/hadoop1-mju
                                                                                                                                             * container name은 hadoop-practice
                                                                                                                                             * hadoop-1.2.1 package는 /root/hadoop 디렉토리(symbolic link)에 설치되어 있음
실행환경 구성
Hadoop installation directory structure
  





                                                                                                                                             * bin
                                                                                                                                             * Hadoop 실행파일들
                                                                                                                                             * conf
                                                                                                                                             * 설정 파일들
                                                                                                                                             * hadoop-env.sh
                                                                                                                                             * 하둡을 실행하는 쉘 스크립트
                                                                                                                                             * JDK 경로
                                                                                                                                             * Class path
                                                                                                                                             * daemon start-up options
                                                                                                                                             * masters
                                                                                                                                             * 보조 네임노드를 실행할 서버
                                                                                                                                             * slaves
                                                                                                                                             * 데이터노드(태스크 트래커)를 실행할 서버
                                                                                                                                             * core-site.xml
                                                                                                                                             * HDFS에서 사용할 환경 정보
                                                                                                                                             * hadoop-core-1.2.1jar에 포함된 hdfs-default.xml을 오버라이드
                                                                                                                                             * mapred-site.xml
                                                                                                                                             * MapReduce에서 사용할 환경 정보
                                                                                                                                             * hadoop-core-1.2.1jar에 포함된 mapred-default.xml을 오버라이드
SSH 테스트
  

                                                                                                                                             * Passwordless ssh가 필요함
                                                                                                                                             * $ service ssh start
                                                                                                                                             * $ ps -ef | grep ssh
                                                                                                                                             * $ ssh localhost
                                                                                                                                             * $ exit                        // disconnect from localhost
여러개의 터미널로 컨테이너 접근하기
실행중인 docker container 접속하기
docker exec로 실행
                                                                                                                                             * $ sudo docker exec -i -t hadoop-practice /bin/bash




Hadoop 실행하기
NameNode 포맷하기
                                                                                                                                             * 하둡 설치 디렉토리에서 실행
                                                                                                                                             * ~/hadoop#에서 실행
                                                                                                                                             * ./bin//hadoop namenode -format
                                                                                                                                             * 결과가 core-site/xml에 지정한 /root/data-hadoop/ 디렉토리에 저장됨
                                                                                                                                             * /root/data-hadoop
                                                                                                                                             * /dfs
                                                                                                                                             * /name
                                                                                                                                             * /current
                                                                                                                                             * VERSION
                                                                                                                                             * edits
                                                                                                                                             * fsimage
                                                                                                                                             * fstime
                                                                                                                                             * /image


Hadoop 데몬 실행 및 확인
                                                                                                                                             * 하둡 설치 디렉토리에서 실행
                                                                                                                                             * ./bin/start-all.sh
                                                                                                                                             * jps                // java process를 확인하는 명령어
                                                                                                                                             * NameNode
                                                                                                                                             * DataNode
                                                                                                                                             * SecondaryNameNode
                                                                                                                                             * TaskTracker
                                                                                                                                             * JobTracker
                                                                                                                                             * VM IP 연결
https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=joonee14&logNo=220460723097
172.17.0.2:50070


Linux Server - Docker - Hadoop 인터페이스 작성하기
sudo docker run -i -t --name hadoop -p 8080:50070 -p 8081:50030 jiksoo75/hadoop1-mju


Hadoop의 50070이 Docker Host의 8080에 Port forwarding 




Hadoop이 사용하는 포트 리스트
https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=rusell&logNo=60210161939


Port                        Service
50070, 54310                NameNode
54310                fs.default.name
50090                        Secondary NameNode
50010, 50020, 50075        DataNode
50010                dfs.datanode.address
50020                dfs.datanode.ipc.address
50070                dfs.http.address
50075                dfs.datanode.http.address
50090                dfs.secondary.http.address
50030, 54311                JobTracker
50030                mapred.job.tracker.http.address
54311                mapred.job.tracker
50060                        TaskTracker
60000, 60010                HMaster
        60000                hbase.master.port
        60010                hbase.master.info.port
60020, 60030                RegionServer
        60020                hbase.regionserver.port
        60030                hbase.regionserver.info.port
02181                        ZooKeeper




docker-proxy로 port forwarding하기
https://bluese05.tistory.com/53
docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 8080 -container-ip 172.17.0.2 -container-port 80




하둡 예제 실행
WordCount
                                                                                                                                             * Hadoop 설치 디렉토리에서 실행
  

                                                                                                                                             * hadoop fs -put conf/hadoop-env.sh input
                                                                                                                                             * conf/hadoop-env.sh > input 파일 올리기
                                                                                                                                             * WordCount 실행
                                                                                                                                             * ./bin/hadoop jar hadoop-examples-1.2.1.jar wordcount input output
                                                                                                                                             * hadoop-examples-1.2.1.jar에 있는 wordcount라는 예제를 실행
                                                                                                                                             * input: 집어넣을 파일 이름
                                                                                                                                             * output: 결과가 출력될 디렉토리 이름
  

                                                                                                                                             * 실행결과 확인하기
                                                                                                                                             * ./bin/hadoop fs -ls output
                                                                                                                                             * ./bin/hadoop fs -cat output/~~~name~~~ | head


Calculate PI with monte-carlo simulation
                                                                                                                                             * ./bin/hadoop jar hadoop-examples-1.2.1.jar pi 4 5000
Example HELP
                                                                                                                                             * ./bin/hadoop jar hadoop-examples-1.2.1.jar




Hadoop 종료
                                                                                                                                             * Daemon 종료
                                                                                                                                             * ./bin/stop-all.sh
                                                                                                                                             * 컨테이너 종료
                                                                                                                                             * interactive mode
                                                                                                                                             * exit
                                                                                                                                             * background mode
                                                                                                                                             * sudo docker stop container-name
                                                                                                                                             * 다시 시작
                                                                                                                                             * Docker container
                                                                                                                                             * sudo docker start container-name
                                                                                                                                             * Daemon (in container)
                                                                                                                                             * service ssh start
                                                                                                                                             * ./bin/start-all.sh
________________
HDFS 기본 명령어 실습
HDFS 명령어
./bin/hadoop fs -cmd [args]
                                                                                                                                                * cmd: 명령어
                                                                                                                                                * args: 명령 수행에 필요한 파라미터
./bin/hadoop fs -help


ls
                                                                                                                                                * 디렉토리에 있는 파일의 정보를 출력하거나 특정한 파일을 지정해 정보를 출력하는 명령어
                                                                                                                                                * 권한 정보, 소유자, 소유 그룹, 생성일자, 바이트 수 등을 확인 가능
lsr
                                                                                                                                                * 현재 디렉토리의 하위 디렉토리 정보까지 출력
                                                                                                                                                * ./bin/hadoop fs -lsr output
du
                                                                                                                                                * 지정한 디렉토리나 파일의 사용량을 확인 (byte 단위)
                                                                                                                                                * ./bin/hadoop fs -du
dus
                                                                                                                                                * 전체 합계 용량만 출력
                                                                                                                                                * ./bin/hadoop fs -dus
cat
                                                                                                                                                * 지정한 파일의 내용을 화면에 출력
                                                                                                                                                * ./bin/hadoop fs -cat input
text
                                                                                                                                                * zip 파일 형태로 압축된 파일도 텍스트 화면으로 출력
mkdir
                                                                                                                                                * 지정한 경로에 디렉토리를 생성
                                                                                                                                                * ./bin/hadoop fs -mkdir testDir
                                                                                                                                                * 이미 존재하는 디렉토리를 생성하려는 경우
  

put
  

                                                                                                                                                * ./bin/hadoop fs -put conf testDir
                                                                                                                                                * local system의 conf 폴더를  testDir에 올리기
                                                                                                                                                * ./bin/hadoop fs -ls testDir
./bin/hadoop fs -ls testDir/conf
copyFromLocal
                                                                                                                                                   * put과 동일
get
                                                                                                                                                   * HDFS에 저장된 데이터를 로컬 파일 시스템으로 복사
                                                                                                                                                   * checksum을 숨김파일로 저장하고 해당 파일을 조회할 때 checksum을 이용해 무결성 확인
                                                                                                                                                   * ./bin/hadoop fs -get output/part-r-00000 wordcount_output
cat wordcount_output
getmerge
                                                                                                                                                      * 지정된 경로에 있는 모든 파일의 내용을 합친 후, 로컬 파일 시스템에 단 하나의 파일로 복사
                                                                                                                                                      * ./bin/hadoop fs-getmerge output/_logs/history wordcount_log
                                                                                                                                                      * head -5 wordcount_log
cp
                                                                                                                                                      * 디렉토리 및 파일을 복사 (HDFS 안에서)
                                                                                                                                                      * ./bin/hadoop fs -cp input input.bak
copyToLocal
                                                                                                                                                      * get과 동일
mv
                                                                                                                                                      * 디렉토리 및 파일을 이동 (HDFS 안에서)
                                                                                                                                                      * ./bin/hadoop fs -mv source destination
moveFromLocal
                                                                                                                                                      * put과 동일하나
                                                                                                                                                      * 대상파일을 이동 후 삭제
rm
                                                                                                                                                      * 디렉토리나 파일 삭제
                                                                                                                                                      * 디렉토리는 비어있어야 함
rmr
                                                                                                                                                      * 비어있지 않은 디렉토리 삭제
tail
                                                                                                                                                      * 지정한 파일의 마지막 1KB를 출력
                                                                                                                                                      * ./bin/hadoop fs -tail output/part-r-00000
chmod
  
                                                                                                                                                      * 파일이나 디렉토리의 권한 변경
                                                                                                                                                      * 슈퍼유저, 대상 파일 소유자만 가능
                                                                                                                                                      * -R 옵션을 사용할 경우 재귀적으로 실행
                                                                                                                                                      * ./bin/hadoop fs -chmod a+w input.bak
chown
                                                                                                                                                      * 지정한 파일과 디렉토리에 대한 소유권 변경
                                                                                                                                                      * 존재하지 않는 사용자나 그룹도 가능
                                                                                                                                                      * -R 로 재귀적 실행
                                                                                                                                                      * ./bin/hadoop fs -chown tester:testerGroup input.bak
chgrp
                                                                                                                                                      * 지정한 파일과 디렉토리에 대한 소유권 그룹만 변경
                                                                                                                                                      * 존재하지 않는 사용자나 그룹도 가능
                                                                                                                                                      * -R 로 재귀적 실행
                                                                                                                                                      * ./bin/hadoop fs -chgrp tester:testerGroup input.bak
권한 변경
                                                                                                                                                      * 있지 않은 사용자나 그룹도 미리 가능하다
                                                                                                                                                      * 이런 이유는 컨셉만 가지고 있을 뿐 실제 유저와 매핑되는 것은 아니기 때문
                                                                                                                                                      * execute permission은 존재는 하나 무시됨.


HDFS 운영 실습
fsck
                                                                                                                                                      * 파일 시스템 체크
                                                                                                                                                      * HDFS에 저장된 파일의 문제 확인
                                                                                                                                                      * ./bin/hadoop fsck /
                                                                                                                                                      * 목표 directory 없이 실행할 경우 도움말이 출력됨
balancer
                                                                                                                                                      * 블록 분포나 복제를 조정한다.
                                                                                                                                                      * hadoop balancer -threshold [threshold]
                                                                                                                                                      * threshold는 블록을 과도하게 사용하고 있는 데이터노드와 정상적인 데이터노드 간 허용되는 사용 비율 차이 (default 10%)
                                                                                                                                                      * 상용 클러스터에서는 데이터노드 중 하나에서 백그라운드로 실행해 두는 것이 좋다.
                                                                                                                                                      * 지속적인 블록 정리
                                                                                                                                                      * 성능에 끼치는 영향은 적음
dfsadmin
                                                                                                                                                      * HDFS 관리자 기능
                                                                                                                                                      * ./bin/hadoop dfsadmin -help
report
                                                                                                                                                      * ./bin/hadoop dfsadmin -report
                                                                                                                                                      * HDFS의 기본적인 정보와 상태를 출력
safemode
                                                                                                                                                      * ./bin/hadoop dfsadmin -safemode
                                                                                                                                                      * Namenode와 Datanode간의 block reporting이 완료되기 전까지의 상태
                                                                                                                                                      * safemode에선 쓰기 금지 (읽기는 가능)
                                                                                                                                                      * 사용자가 직접 제어 가능
                                                                                                                                                      * ./bin/hadoop dfsadmin -safemode enter
                                                                                                                                                      * ./bin/hadoop dfsadmin -safemode leave
saveNamespace
                                                                                                                                                      * ./bin/hadoop dfsadmin -saveNamespace
                                                                                                                                                      * safemode 에서만 실행 가능
                                                                                                                                                      * 로컬 파일시스템에 저장되어 있는 파일 시스템 이미지 파일과 edit 로그를 현재 버전으로 갱신
Quota 설정
Entity count limitation
                                                                                                                                                      * HDFS 디렉토리에 파일들이 과도하게 생성되는 것을 제한할 수 있는 쿼터 설정 명령어 제공
                                                                                                                                                      * 쿼터 수는 지정된 디렉토리까지 포함된 수치
                                                                                                                                                      * 쿼터 적용 확인
                                                                                                                                                      * ./bin/hadoop fs -mkdir quota_test
                                                                                                                                                      * ./bin/hadoop dfsadmin -setQuota 2 quota_test
                                                                                                                                                      * ./bin/hadoop fs -put file1 quota_test/                ## OK
                                                                                                                                                      * ./bin/hadoop fs -put file2 quota_test/                ## ERROR : exceeded
                                                                                                                                                      * ./bin/hadoop dfsadmin -clrQuota quota_test
저장용량 설정
                                                                                                                                                      * HDFS 특정 디렉토리가 지나치게 많은 용량을 차지하지 않도록 설정
                                                                                                                                                      * 기본 용량 = byte
                                                                                                                                                      * 130m         = 130 MB
                                                                                                                                                      * 6g         = 6 GB
                                                                                                                                                      * 3t         = 3 TB
                                                                                                                                                      * ./bin/hadoop dfsadmin -setSpaceQuota 2m quota_test
                                                                                                                                                      * ./bin/hadoop dfsadmin -clsSpaceQuota quota_test
                                                                                                                                                      * 용량이 다 찬 상태에서 올리려고 하면 head만 생성되고 내용은 안 올라간다.
                                                                                                                                                      * 마찬가지로 중간에 차면 그 만큼만 올라가고 도중에 짤린다.




MapReduce
Basic Concepts of Mapreduce
Big data processing


Hadoop project
                                                                                                                                                      * distributed file system
                                                                                                                                                      * framework


MapReduce
                                                                                                                                                      * programming model
                                                                                                                                                      * runtime system
                                                                                                                                                      * parallel close to their data
                                                                                                                                                      * 병렬하게
                                                                                                                                                      * 데이터와 최대한 가깝게 (Network topology: hop counting)
                                                                                                                                                      * Scaleout architecture
                                                                                                                                                      * simply adding commodity servers
                                                                                                                                                      * computation capacity, storage capacity, IO bandwidth


Root of Hadoop (MapReduce)
OSDI’ 2004 Google, Inc. MapReduce


Paper
a programming model and an associated implementation for processing and generating large data sets.


사용자는 다음 기능을 개발해야 함.
                                                                                                                                                      * map function
                                                                                                                                                      * reduce function


입력 출력이 항상 key-value 형태로 표현됨


abstract MapReduce: Communications of the ACM, 2008


Introduction
                                                                                                                                                      * Prior to development of of MapReduce
                                                                                                                                                      * Google implemented hundreds of special-purpose computations
                                                                                                                                                      * large amounts of raw data
                                                                                                                                                      * crawled documents
                                                                                                                                                      * web request logs
                                                                                                                                                      * conceptually straightforward
                                                                                                                                                      * 복잡한 일은 아님
                                                                                                                                                      * input data is usually large
                                                                                                                                                      * 데이터가 대규모
                                                                                                                                                      * computations have to be distributed
                                                                                                                                                      * 분산해서 처리해야 함
                                                                                                                                                      * MapReduce is a programming model and implementation
                                                                                                                                                      * abstraction to express the simple computations
                                                                                                                                                      * hides parallelization, fault tolerance, data distribution
                                                                                                                                                      * Lisp (map, reduce)
                                                                                                                                                      * logical records -> map
                                                                                                                                                      * intermediate key / value
                                                                                                                                                      * MapReduce에서 logical record는 보통 문자 한 줄
                                                                                                                                                      * 같은 키를 가지는 것 끼리 묶어줌
                                                                                                                                                      * 각 reduce는 같은 키를 가지는 값만 전달받는다.
                                                                                                                                                      * combine aggregation
                                                                                                                                                      * 즉, 추상화 레벨을 높여 개발자로 하여금 기능 구현에만 집중하도록 만든 것


Programming Model
                                                                                                                                                      * Map: 사용자가 개발해야 함.
                                                                                                                                                      * input을 intermediate key / value로 바꾸는 작업을 한다.
                                                                                                                                                      * MapReduce가 같은 key끼리 grouping한다.
                                                                                                                                                      * 같은 key끼리는 쪼개져서는 안 됨.
                                                                                                                                                      * Reduce: 사용자가 개발해야 함.
                                                                                                                                                      * merge해서 smaller set of value로 만든다.


Wordcount 예제
  

Input-split: 보통 하나의 블록 단위 (아니어도 되지만, 성능상의 이유로 보통 그러함)
고로 Mapper는 하나의 블록을 받게 됨.


모든 Mapper가 작업을 끝내기 전까지 다음단계로 넘어가지 않는다.


Shuffling: 같은 intermediate key 끼리 묶어줌


Reducing: Reducer는 사용자가 정의한 함수로 들어온 pair들을 하나의 pair(key-value)로 프로세싱한다.


Wordcount MapReduce 프로그래밍 예제
  



Java로 구현된 모습  (Hadoop은 자체적인 Type이 있음)
  

Mapper는 map이라는 함수를 지닌다.
map에 들어오는 parameter는
        key: input-split 에서 value의 위치
        value: 텍스트
        context: MapReduce 실행환경과 communication 하기 위한 context
                context.write(intermediateKey, value)


Reducer는  reduce라는 함수를 지닌다.
<IN_KEY_TYPE, IN_VALUE_TYPE, OUT_KEY_TYPE, OUT_VALUE_TYPE>
Key에 Iterable<IN_VALUE_TYPE>의 형태로 들어온다.


Implementation
Execution overview (Google MapReduce)
                                                                                                                                                      * Input data는 M개의 input split으로 partitioning된다.
                                                                                                                                                      * input split 개수 만큼 in parallel할 수 있다.
                                                                                                                                                      * 보통 크기가 고정
                                                                                                                                                      * 결국 map은 input의 크기만큼 생성(불리게)되게 된다.
                                                                                                                                                      * Reduce
                                                                                                                                                      * intermediate key space를 적절히 partitioning해야 한다.
                                                                                                                                                      * Reduce invocations are distributed by partitioning the intermediate key space into R pieces using a partitioning function.


  



                                                                                                                                                      * Master : Job tracker
                                                                                                                                                      * MapReduce 실행을 관장
                                                                                                                                                      * worker : Task tracker


                                                                                                                                                      * Periodically, the buffered pairs are written to local disk, partitioned into R regions by the partitioning function 주기적으로 버퍼링된 pair는 파티션 기능에 의해 R 영역으로 파티션된 로컬 디스크에 기록됩니다. (map단계가 끝날 때 까지)


  

                                                                                                                                                      * Data에 따라 특정 partition은 없을 수도 있다.
Fault Tolerance
                                                                                                                                                      * Master가 각각의 Worker에 ping한다.
                                                                                                                                                      * 일정시간동안 응답이 없으면 죽은 것으로 판단.
                                                                                                                                                      * mapper의 경우 죽은게 있으면 map task는 완료여부 상관없이 처음부터 다시 시작.
                                                                                                                                                      * machine failed 되었다는 건 해당 machine에 할당 되었던 input-split과 결과물이 날아 갔다는 이야기이다.
                                                                                                                                                      * output은 해당 node에 저장되어 있다.
                                                                                                                                                      * reduce의 경우 죽은게 있으면
                                                                                                                                                      * 완료되지 않은 것은 다시 시작
                                                                                                                                                      * 완료된 것은 그러지 않아도 됨
                                                                                                                                                      * output은 global file system에 저장되어 있다.
                                                                                                                                                      * intermediate data는 사라질 데이터라 보기 때문에 node에 임시로 저장했음.


                                                                                                                                                      * large-scale worker failures에 대해 resilient(탄력적)하다.
Locality
                                                                                                                                                      * Network bandwidth는 한정된 자원
                                                                                                                                                      * Moving computations close to the data
                                                                                                                                                      * map task를 input이 있는 node에 가능한 가깝게 배치시킨다.
  



                                                                                                                                                      * Data Local: 같은 Node에 있음
                                                                                                                                                      * Rack Local: Node는 다르지만, Rack이 같다.
                                                                                                                                                      * 여기서 HDFS의 Block 분산 방식이 나옴
                                                                                                                                                      * Node에는 하나의 블록
                                                                                                                                                      * Rack에는  2개
                                                                                                                                                      * 다른 Rack에 하나 더
Experience in Google
Large-scale indexing
                                                                                                                                                      * benefits
                                                                                                                                                      * 이해하기 쉬워짐
                                                                                                                                                      * 3800 line의 줄이 700 line으로 줄었다.
                                                                                                                                                      * performance가 좋아짐
                                                                                                                                                      * 운영하기 편해졌다.
                                                                                                                                                      * machine failures, slow machines, networking hiccups 문제가 자동으로 처리됨.


이러한 것은: Datacenter를 Computer처럼 사용하기 위해 나옴






Hadoop: HDFS + MapReduce
  

                                                                                                                                                      * namenode와 job submission node는 따로 운영도 가능하나 보통 같은 machine에 운영한다.
                                                                                                                                                      * 각각의 slave node는 datanode와 tasktracker가 함께 실행되어야 한다.
                                                                                                                                                      * MapReduce 처리를 위한 필수 사항
                                                                                                                                                      * tasktracker가 없는 node는 jobtracker가 node를 인식할 수 없다
                                                                                                                                                      * tasktracker는 task 실행 주체.
                                                                                                                                                      * datanode가 없는 node는 namenode가 node를 인식할 수 없다.
                                                                                                                                                      * Hadoop MapReduce는 Java와 다른 자체적인 Type를 가진다.
                                                                                                                                                      * Network serialization 최적화
                                                                                                                                                      * String         >Text
                                                                                                                                                      * int        > IntWritable
                                                                                                                                                      * long        > LongWritable
                                                                                                                                                      * etc …
JobTracker
                                                                                                                                                      * farms out MapReduce tasks (cluster) 경작
                                                                                                                                                      * ideally
                                                                                                                                                      * input data가 있는 node
                                                                                                                                                      * 아니면 적어도 same rack
                                                                                                                                                      * Data Locality
                                                                                                                                                      * JobTracker a point of failure
                                                                                                                                                      * JobTracker 하나가 죽으면 전체가 실패
                                                                                                                                                      * HDFS의 NameNode와 같다.
                                                                                                                                                      * Steps of MapReduce job processing
                                                                                                                                                      1. client application submit job to JobTracker
                                                                                                                                                      2. JobTracker는 NameNode한테 데이터가 어디있는지 질의
                                                                                                                                                      3. available slots at of near the input data
                                                                                                                                                      1. available slots: 각각 TaskTracker는 configuration에 한 번에 실행 가능한 task (Mapper, Reducer)  수가 제한되어 있음.
                                                                                                                                                      4. JobTracker는 TaskTracker를 선택하여 task를 각각 TaskTracker에게 전달
                                                                                                                                                      5. TaskTracker는 생존신고(Heartbeat)를 JobTracker에게 보낸다.
                                                                                                                                                      1. 만약 생존신고가 특정 기간 이상 없으면 죽은것으로 판단
해당 Job을 다른 TaskTracker에게 스케줄링 한다.
                                                                                                                                                         6. 만약 task가 실패하면 TaskTracker는 JobTracker에게 보고한다.
JobTracker는 
                                                                                                                                                            1. 다시 job을 다른 TaskTracker에게 submit (resubmit)
                                                                                                                                                            2. 계속 죽으면 blacklist에 해당 TaskTracker나 특정 레코드를 피해야 할 것(avoid)으로 등록할 수 있다. 
                                                                                                                                                            7. when the work is completed, the JobTracker updates it status
                                                                                                                                                            8. client applications can poll the JobTracker for information
  

                                                                                                                                                            * copy job resources: mapper, reducer가 정의된 jar 파일 등.
                                                                                                                                                            * 실행할 node가 정해져 있지 않으므로 shared file system에 저장
                                                                                                                                                            * 8: TaskTracker는 9: launch를 위해 shared file system에 올라온 job resource를 가져온다.
                                                                                                                                                            * 6과 7 사이에는 JobTracker가 TaskTracker에게 Job을 할당하는 장면이 생략됨.


TaskTracker
                                                                                                                                                            * 담당하는 일: Map, Reduce, Shuffle - from a JobTracker
                                                                                                                                                            * 각각의 TaskTracker는 static하게 동시에 처리할 수 있는 작업의 수가 정해져 있다. = Slots
                                                                                                                                                            * 이는 각각의 node의 spec이 비슷하다 가정한 설계
                                                                                                                                                            * separate JVM process를 spawn해서 작업을 실행
                                                                                                                                                            * 작업이 죽더라도 tasktracker 자체가 죽지 않음
                                                                                                                                                            * process들을 monitoring하고 output과 exit code를 capturing한다.
                                                                                                                                                            * process가 끝나면 successfully or not을 JobTracker에게 보고한다.
                                                                                                                                                            * heartbeat message를 JobTracker에게 보낸다. (usually every few minutes)
                                                                                                                                                            * number of available slot 등의 information이 담긴다.
                                                                                                                                                            * JobTracker는TaskTracker를 사용하기 위해
                                                                                                                                                            * Data Locality를 고려
                                                                                                                                                            * TaskTracker의 slots 여유분을 알아야 함.
A Weather Dataset Case Study
MapReduce
                                                                                                                                                            * 단순하지만 useful programming을 하지 못할 정도로 심플하지는 않음
                                                                                                                                                            * support language
                                                                                                                                                            * Java, Ruby, Python, etc
                                                                                                                                                            * inherently parallel
                                                                                                                                                            * large-scale data analysis
                                                                                                                                                            * 데이터 규모가 커질수록 진가를 발휘함
A Weather Dataset
                                                                                                                                                            * Weather data analysis program
                                                                                                                                                            * large volume of log data
                                                                                                                                                            * semi-structured & record-oriented
                                                                                                                                                            * Data Format
                                                                                                                                                            * National Climatic Data Center (NCDC)
                                                                                                                                                            * semi-structure (ASCII)
                                                                                                                                                            * line = record
                                                                                                                                                            * 풍부한 데이터셋으로 구성되어 있으며 다양한 option과 variable data length를 지닌다.
                                                                                                                                                            * 여기서는 temperature만 본다
                                                                                                                                                            *                                                                                                                                                                  * 빨간 사각형이 한 줄 (a single line)
                                                                                                                                                               * 각각의 line은 여러 조각들로 구성됨
                                                                                                                                                               * positioning data(delimiter가 없음)
                                                                                                                                                               * 수 만개의 weather station에서 정보가 만들어짐
                                                                                                                                                               * 엄청난 수의 작은 파일들
                                                                                                                                                               * preprocessing 처리의 효율을 위해 하나의 파일로 합친다.
Analyzing the Data with Unix Tools
                                                                                                                                                               * What is the highest recorded global temperature for each year in the dataset?
                                                                                                                                                               * classic tool로 처리하는 방법? awk
                                                                                                                                                               *                                                                                                                                                                     * awk는 line by line으로 처리하는 툴
                                                                                                                                                                  * temp가 9999이면 관측이 안 됨 (MISSING)
                                                                                                                                                                  * q code는 { 0, 1, 4, 5, 9 }만 acceptable
                                                                                                                                                                  * loop를 돌면서 처리함 순차 처리함
                                                                                                                                                                  * 42분 걸림
                                                                                                                                                                  * To speed up the processing = in parallel
                                                                                                                                                                  * Potential Problems
                                                                                                                                                                  * 똑같은 사이즈로 쪼개기 힘들다.
                                                                                                                                                                  * 연도별로 사이즈가 다를 수 있다.
                                                                                                                                                                  * 가장 큰 조각을 처리하는 프로세스가 전체 수행 시간을 결정함
                                                                                                                                                                  * 전체 input을 같은 크기의 chunk로 쪼개서 처리하는 것이 더 좋은 방법일 것 
                                                                                                                                                                  * fixed-size chunks
                                                                                                                                                                  * Combining the results from independent processes may require further processing
  



                                                                                                                                                                  * parallel 의 주요 쟁점 : coordination & reliability
Analyzing the Data with Hadoop
                                                                                                                                                                  * Expressing the query as a MapReduce job
                                                                                                                                                                  * processing을 two phase: map과 reduce로 나눈다.
                                                                                                                                                                  * 각 phase는 key-value pair를 input과 output으로 가짐
                                                                                                                                                                  * type는 programmer가 선택
                                                                                                                                                                  * input to the map phase is raw NCDC data
                                                                                                                                                                  * text input
                                                                                                                                                                  * key는 offset of the beginning of the line from beginning of the file
                                                                                                                                                                  * 안 씀.
                                                                                                                                                                  * input: ( offset(long), text )
                                                                                                                                                                  * map function
  
                                                                                                                                                                     * pull year, air temperature
                                                                                                                                                                     * filtering
                                                                                                                                                                     * bad recording ex: 9999
                                                                                                                                                                     * ( year, temperature )
                                                                                                                                                                     * Shuffle & Reduce
  
                                                                                                                                                                        * Reduce:
                                                                                                                                                                        * 각 년도의 최고 온도를 뽑는다.
  



Mapper Source
  



context.write


Reduce source
  



Application source
  

job.waitForCompletion( boolean : willGenerateVerboseOutput? ) : succes ? true : false.


Java MapReduce
이 모든걸 jar 파일로 패키징해야 한다.
                                                                                                                                                                        * Hadoop을 구성하는 어느 node에서든 실행할 수 있다는 걸 염두해야 한다.
                                                                                                                                                                        * Hadoop will distribute it around the cluster
                                                                                                                                                                        * job.setJarByClass() 를 이용하여 class를 전달 할 수 있다. Hadoop은 관련 JAR 파일을 찾는데 사용할 것이다.
                                                                                                                                                                        * Job job = new Job();
job.setJarByClass(MaxTemperature.class);
job.setJobName(“Max temperature”);


                                                                                                                                                                           * addInputPath()
한 번 이상 실행된다. 여러개의 파일을 지정할 수 있다.
FileInputFormat
                                                                                                                                                                              * single file
                                                                                                                                                                              * directory
                                                                                                                                                                              * file path pattern
                                                                                                                                                                              * setOutputPath()
한 번만 실행된다
                                                                                                                                                                                 * 신규 directory여야 한다.
                                                                                                                                                                                 * 여러개의 output file이 생성될 것이다.
  

                                                                                                                                                                                 * Specifying the map and reduce types
                                                                                                                                                                                 *                                                                                                                                                                                       * Control the output types for the reduce functions
                                                                                                                                                                                    * Reduce가 생성할 data type과 반드시 맞추어주어야 함.
  
                                                                                                                                                                                    * map output type도 Reduce와 대개 같음.
만약 다를 경우 아래 method로 지정해야 함.
                                                                                                                                                                                       * job.setMapOutputKeyClass()
                                                                                                                                                                                       * job.setMapOutputValueClass()
                                                                                                                                                                                       * Input Type
                                                                                                                                                                                       * default : TextInputFormat
                                                                                                                                                                                       * key : offset
                                                                                                                                                                                       * value : 한 줄
                                                                                                                                                                                       * Running the MapReduce Job
                                                                                                                                                                                       * 위의 작업이 다 끝나면 ready to run
                                                                                                                                                                                       * waitForCompletion( boolean flag )
Job을 submit하고 끝날때까지 기다린다.
                                                                                                                                                                                          * flag: output이 많이 나오게 할 것인가?
                                                                                                                                                                                          * return:
                                                                                                                                                                                          * true        : 성공
                                                                                                                                                                                          * false        : 실패
                                                                                                                                                                                          * Output은 디렉토리, Reducer당 하나의 파일이 생성됨.
                                                                                                                                                                                          * 키 당 reducer 하나씩 여러개 줄 수 도 있음.
                                                                                                                                                                                          * job has a single reducer, so we find a single file, part-r-00000
  


  



extends Mapper<InputKey, InputValue, OutputKey, OutputValue>
                                                                                                                                                                                             * 보통 Input이 TextInputFormat
                                                                                                                                                                                             * LongWritable
                                                                                                                                                                                             * Text


  

extends Reducer<InputKey, InputValue, OutputKey, OutputValue>
                                                                                                                                                                                             * reducer의 input은 mapper의 output
                                                                                                                                                                                             * 단, 실제 함수에 들어오는 InputValue는 Iterable이다.




Hadoop은 0.20 API와 1.x, 2.x API 가 서로 다르다.
  

                                                                                                                                                                                             * Different
https://hadoopbeforestarting.blogspot.com/2012/12/difference-between-hadoop-old-api-and.html
                                                                                                                                                                                                * New API
                                                                                                                                                                                                * org.apache.hadoop.mapreduce.*
                                                                                                                                                                                                * context
                                                                                                                                                                                                * Old API
                                                                                                                                                                                                * org.apache.hadoop.mapred.*
                                                                                                                                                                                                * OutputCollector
                                                                                                                                                                                                * Reporter
                                                                                                                                                                                                * New API를 사용해야 함.
Passing parameters to Mapper and Reducer
                                                                                                                                                                                                * New API에는 Mapper와 Reducer에게 parameter를 전달할 수 있는 별도의 수단을 제공해준다.
                                                                                                                                                                                                * Setting the parameter
before launching the job using the new MR API
  
                                                                                                                                                                                                * Getting the parameter
the context is passed to the setup, map, reduce, and cleanup functions
  


Scaling Out
Data flow of MapReduce
  



                                                                                                                                                                                                   1. Client가 job 수행을 요청
                                                                                                                                                                                                   2. Hadoop은 map, reduce task를 만든다.
                                                                                                                                                                                                   1. jobtracker가 tasktrackers의 slot을 토대로 scheduling (Hadoop 1.0)
                                                                                                                                                                                                   2. Hadoop 2.0에서는 YARN에 의해 다른 방식으로  scheduling됨.
                                                                                                                                                                                                   3. 만약 fails가 일어나면 automatically하게 rescheduled 된다.
                                                                                                                                                                                                   3. 고정된 크기의 input split으로 쪼갠다.
                                                                                                                                                                                                   1. node들이 비슷한 사양이라는 가정하에 설계된 형태
                                                                                                                                                                                                   2. 사용자가 정의한 각각의 record 단위로 split된다.
                                                                                                                                                                                                   1. 하나의 input split당 하나의 mapper가 담당
                                                                                                                                                                                                   2. 각 record당 mapper가 여러번 실행
                                                                                                                                                                                                   3. 여기서는 block 단위(64MB)
                                                                                                                                                                                                   1. 너무 작으면 과도하게 많은 mapper가 생성됨
                                                                                                                                                                                                   4. data locality optimization을 수행한다.
HDFS는 저비용의 하드웨어로 구성된 클러스터이므로 bandwidth가 제한되어 있다.
때문에 한정된 bandwidth를 아끼고 효율을 높이기 위한 수단
  
                                                                                                                                                                                                      1. Data-Local
                                                                                                                                                                                                      2. Rack-Local
                                                                                                                                                                                                      3. Off-Rack
                                                                                                                                                                                                      5. 왜 optimal split size = same as block size
                                                                                                                                                                                                      1. 엄밀히 말하면 독립적 개념
                                                                                                                                                                                                      1. input split = MapReduce에서 다루는 크기
                                                                                                                                                                                                      2. block = HDFS가 관리하는 단위 크기
                                                                                                                                                                                                      2. 하나의 node에 저장되어있음을 보장할 수 있는 largest size 이다.
                                                                                                                                                                                                      1. 만약 input split에 두 개 이상의 block으로 구성되면 task 하나 수행에 필요한 input split이 여러 node에 걸쳐 있을 수 있다. 
                                                                                                                                                                                                      1. 최적화된 data locality 수행이 어려워짐.
                                                                                                                                                                                                      2. network transfer 가 요구됨
                                                                                                                                                                                                      2. input split이 block보다 작은 경우
                                                                                                                                                                                                      1. 관리해야 할 map task가 많아진다.
                                                                                                                                                                                                      2. overhead가 커짐.
                                                                                                                                                                                                      6. Map task는 실행 결과를 local disk에 저장
                                                                                                                                                                                                      1. intermediate output
                                                                                                                                                                                                      1. HDFS에 저장하면 overkill
replication등의 필요로 하지 않는 과도한 HDFS기능들이 수행됨
                                                                                                                                                                                                         2. 어차피 failure가 일어나면 다른 node에서 다시 실행하므로 intermediate output을 recreate해야한다.
                                                                                                                                                                                                         1. 기존의 intermediate output이 쓸모없어진다.
                                                                                                                                                                                                         7. Reduce는 data locality advantage를 가질 수 없음
                                                                                                                                                                                                         1. 어차피 network로 transfer해야 함.
                                                                                                                                                                                                         1. 때로는 모든 것이
                                                                                                                                                                                                         2. MapReduce에서 가장 bottleneck이 발생하는 부분은 shuffling, reduce이다.
                                                                                                                                                                                                         2. 결과물은 HDFS에 reliability하게 저장됨
                                                                                                                                                                                                         8. Reduce의 숫자는 프로그래머가 정해준다.
                                                                                                                                                                                                         1. 하나 이상, intermediate data의 key domain 개수이하
                                                                                                                                                                                                         1. job의 data input과 상관이 없다.
                                                                                                                                                                                                         2. Mapper는 전체 input split 개수에 의해 자동으로 정해짐
                                                                                                                                                                                                         9. multiple reducers
                                                                                                                                                                                                         1. map은 task output을 partition한다.
                                                                                                                                                                                                         1. 각각의 partition은 각각 reduce task가 할당됨
                                                                                                                                                                                                         2. 여러 partition에 걸쳐서 같은키가 존재할 수는 없다!
                                                                                                                                                                                                         2. 특정한 key에 해당하는 모든 값들은 single partition에 들어간다.
                                                                                                                                                                                                         1. 같은 key는 같은 reducer에게 간다는 것.
                                                                                                                                                                                                         2. 이를 shuffle이라 함(shuffling)
                                                                                                                                                                                                         3. output file은 reducer 개수만큼 나옴
                                                                                                                                                                                                         10. zero reduce task
                                                                                                                                                                                                         1. map 단계만 필요로 하는 job은 reducer없이 수행가능하다.
                                                                                                                                                                                                         1. post processing이라든가 등등…
                                                                                                                                                                                                         2. 이 경우 map task가 끝난 결과물이 바로(directly) HDFS에 저장됨.
                                                                                                                                                                                                         3. shuffling이 없음
                                                                                                                                                                                                         4. 이걸 map-only job
Data Flow Diagram
Single Reduce Job 
  

Multiple Reduce tasks
  

Zero reduce task
  

Combiner
  
                                                                                                                                                                                                         * Combiner functions
                                                                                                                                                                                                         * Map > Reducer에서 대량의 transfer가 이루어질 수밖에 없음
                                                                                                                                                                                                         * combiner는 Map 과 Reducer 사이에 껴서 optimization을 수행
                                                                                                                                                                                                         * combiner는 Map이 실행되는 node에 붙어서 같이 실행됨
                                                                                                                                                                                                         * combiner가 얼마나 불릴지 Hadoop은 보장 안함.
                                                                                                                                                                                                         * 즉 프로그래머는 combiner가 없더라도 잘 동작하게끔 만들어야 한다.
  

                                                                                                                                                                                                         * Combiner는 Reduce 작업의 일부를 미리 처리하여 transfer할 data의 양을 줄임.
                                                                                                                                                                                                         * it can help cut down the amount of data shuffled between mappers and reducers.
                                                                                                                                                                                                         * combiner는 intermediate data가 자신의 output으로 대체되더라도 reducer가 의도한 값을 낼 수 있도록 디자인되어야 함.
즉, reduce task는 다음을 만족해야 한다.
                                                                                                                                                                                                            * commutative
                                                                                                                                                                                                            * 2+3 = 3+2
                                                                                                                                                                                                            * associate
                                                                                                                                                                                                            * (1+2)+3 = 1+(2+3)
                                                                                                                                                                                                            * 예를 들어 평균구하기는 적용이 불가능함.
                                                                                                                                                                                                            * 따라서 이런 경우 reducer를 combiner function으로 대체할 수 없다.
Combiner 적용 례
  

                                                                                                                                                                                                            * 이 경우에는 Reducer와 Combiner가 동일한 logic을 공유하므로 그냥 가져다 씀


Hadoop Streaming
                                                                                                                                                                                                            * Java가 아닌 다른 언어로 만들어진 프로그램을 MapReduce로 연결하는 것
                                                                                                                                                                                                            * Unix standard streams을 이용해야 함.
                                                                                                                                                                                                            * C의 경우 stdio를 말함
                                                                                                                                                                                                            * text processing
                                                                                                                                                                                                            * key <tab> value (key-value pair to single of tab-delimited line)
                                                                                                                                                                                                            * input > scanf(“%s\t”%s”, key, value)
                                                                                                                                                                                                            * output > printf(“%s\t”%d”, key, value)
                                                                                                                                                                                                            * python, ruby, etc ….
Ruby implementation
Mapper
  

Reducer
  

                                                                                                                                                                                                            * iteration 처리는 그저 같은 key를 가지는 key-value-pair를 여러번 입력받아서 처리함


Unix pipeline으로 simulation 하는 모습
  



Hadoop으로 실행하는 모습
  



Hadoop Cluster에서 실행하는 모습
  

-files option으로 어떤 파일들을 shared storage에 올려야 하는지 지정
Python Implementation
Mapper
  

Reducer
  





정리
                                                                                                                                                                                                            * MapReduce가 왜 나왔는가
                                                                                                                                                                                                            * Google에서 동작하는 모습
                                                                                                                                                                                                            * BigData를 처리할 때 
                                                                                                                                                                                                            * 분산 저장: HDFS
                                                                                                                                                                                                            * 분산 처리: MapReduce
                                                                                                                                                                                                            * cloud programming model
                                                                                                                                                                                                            * block size = input split size
                                                                                                                                                                                                            * why?
                                                                                                                                                                                                            * HDFS는 분산 저장이 용이하지만
MapReduce는 Reduce단계에서 분산처리가 어려워 병목현상발생
                                                                                                                                                                                                               * Combiner로 shuffling단계의 data transfer를 줄일 수 있다.
                                                                                                                                                                                                               * 어떻게 분산된 환경(cloud)에서 데이터를 처리할 것인가?
                                                                                                                                                                                                               * = MapReduce가 한 가지 답을 제시함


[a]contention: 경합
[b]PV: Paravirtualization
[c]HVM: Hardware Virtual Machine